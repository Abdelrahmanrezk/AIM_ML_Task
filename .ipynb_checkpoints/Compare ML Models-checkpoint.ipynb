{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd499258",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from data_shuffling_split import *\n",
    "from features_extraction import *\n",
    "from data_preprocess import *\n",
    "from ml_modeling import *\n",
    "from configs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7501380",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_score(model, x_train, y_train, x_val, y_val, x_test, y_tes):\n",
    "    \n",
    "    print(\"On Training set\\n\")\n",
    "    f1_score_result(model, x_train, y_train)\n",
    "    print(\"=\"*50)\n",
    "    print(\"On Validation set \\n\")\n",
    "    f1_score_result(model, x_train, y_train)\n",
    "    print(\"=\"*50)\n",
    "    print(\"On Training \\n\")\n",
    "    f1_score_result(model, x_train, y_train)\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a955ff7",
   "metadata": {},
   "source": [
    "# Tokenize All data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49e7675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Validation data\n",
    "strat_train_set = read_csv(\"train/strat_train_set.csv\")\n",
    "x_train_text, x_val_text, y_train, y_val = prepare_data(strat_train_set)\n",
    "\n",
    "# Test\n",
    "strat_test_set = pd.read_csv(\"dataset/test/strat_test_set.csv\")\n",
    "x_test_text, y_test = list(strat_test_set['text']), strat_test_set['dialect_l_encoded'].values\n",
    "\n",
    "\n",
    "x_train_text_tokenized = tokenize_using_nltk_TreebankWordTokenizer(x_train_text)\n",
    "\n",
    "print(\"Before Tokenization : \\n\", x_train_text[:3])\n",
    "print(\"=\"*50)\n",
    "print(\"After Tokenization : \\n\", x_train_text_tokenized[:3])\n",
    "print(\"=\"*50)\n",
    "\n",
    "x_val_text_tokenized = tokenize_using_nltk_TreebankWordTokenizer(x_val_text)\n",
    "\n",
    "print(\"Before Tokenization : \\n\", x_val_text[:3])\n",
    "print(\"=\"*50)\n",
    "print(\"After Tokenization : \\n\", x_val_text_tokenized[:3])\n",
    "\n",
    "\n",
    "x_test_text_tokenized = tokenize_using_nltk_TreebankWordTokenizer(x_test_text)\n",
    "\n",
    "print(\"Before Tokenization : \\n\", x_test_text[:3])\n",
    "print(\"=\"*50)\n",
    "print(\"After Tokenization : \\n\", x_test_text_tokenized[:3])\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ac6ec3",
   "metadata": {},
   "source": [
    "# Abo Bakr Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b3636ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Tokenization : \n",
      " ['ياكثرهم في زمانك وياقلهم في وفاك : ياما سمعنا القصايد لكنها ما تفيد العذر والغدر واضح تجني طريق الهلاك : اما حفظت المواصل والا خسرت الرصيد', 'حسابشخصي انزين انت الحين ما عرفت التسعيره عشان تقول له go head شلون تبي السياره تستوي ؟ ', 'حسابشخصي ماعندكمش مطبخ في حوش فيه جو را 😂 ']\n",
      "==================================================\n",
      "After Tokenization : \n",
      " [['ياكثرهم', 'في', 'زمانك', 'وياقلهم', 'في', 'وفاك', ':', 'ياما', 'سمعنا', 'القصايد', 'لكنها', 'ما', 'تفيد', 'العذر', 'والغدر', 'واضح', 'تجني', 'طريق', 'الهلاك', ':', 'اما', 'حفظت', 'المواصل', 'والا', 'خسرت', 'الرصيد'], ['حسابشخصي', 'انزين', 'انت', 'الحين', 'ما', 'عرفت', 'التسعيره', 'عشان', 'تقول', 'له', 'go', 'head', 'شلون', 'تبي', 'السياره', 'تستوي', '؟'], ['حسابشخصي', 'ماعندكمش', 'مطبخ', 'في', 'حوش', 'فيه', 'جو', 'را', '😂']]\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "number_of_features = 100\n",
    "max_len_str = 64\n",
    "\n",
    "word_to_vec_model = load_word2vec_model(\"models/word2vec/bakrianoo_unigram_cbow_model/full_uni_cbow_100_twitter.mdl\")\n",
    "\n",
    "X_train_embed_matrix = text_to_matrix_using_word2vec(word_to_vec_model, x_train_text_tokenized, max_len_str)\n",
    "X_val_embed_matrix = text_to_matrix_using_word2vec(word_to_vec_model, x_val_text_tokenized, max_len_str)\n",
    "x_test_embed_matrix = text_to_matrix_using_word2vec(word_to_vec_model, x_test_text_tokenized, max_len_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b6469b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test using AdaBoostClassifier \n",
    "\n",
    "model_path    = \"bakr/AdaBoostClassifier__f1_0.325_ml.sav\"\n",
    "model = pickle_load_model(\"models/ml_models/\" + model_path)\n",
    "\n",
    "_ = train_val_test_score(model, X_train_embed_matrix, y_train, X_val_embed_matrix, y_val, \n",
    "                         x_test_embed_matrix, y_tes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f297cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test using Logistic Regression \n",
    "model_path    = \"bakr/unigram_100d_lg_cls_model_f1_0.366.sav\"\n",
    "model = pickle_load_model(\"models/ml_models/\" + model_path)\n",
    "\n",
    "_ = train_val_test_score(model, X_train_embed_matrix, y_train, X_val_embed_matrix, y_val, \n",
    "                         x_test_embed_matrix, y_tes):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cc1915",
   "metadata": {},
   "source": [
    "#  Rezk Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5c24f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9164, 19200)\n",
      "==================================================\n",
      "[ 0.629     1.157    -0.6753    0.2048    0.2107    0.516    -0.6455\n",
      "  0.669    -0.72      1.04      0.2937   -0.4473   -0.2487    0.1098\n",
      " -0.1501    0.625     0.012115  0.2568   -1.126     0.2261   -0.08954\n",
      "  0.4692    0.1472    0.4668   -0.0946    0.3938    0.1757    0.413\n",
      " -0.189     0.03577  -0.816     0.8457   -0.3623   -0.564     0.619\n",
      "  0.3655    0.714    -0.3547    0.0713    1.005     0.594     0.671\n",
      "  0.7793    0.1586    0.2812   -0.11224  -0.7334    0.2106    0.4324\n",
      "  0.941   ]\n"
     ]
    }
   ],
   "source": [
    "number_of_features = 100\n",
    "max_len_str = 64\n",
    "\n",
    "word2vec_path = \"rezk_unigram_CBOW_model/train_word2vec_cbow__window_3_min_count_300\"\n",
    "word_to_vec_model = load_word2vec_model(\"models/word2vec/\" + word2vec_path)\n",
    "\n",
    "X_train_embed_matrix = text_to_matrix_using_word2vec(word_to_vec_model, x_train_text_tokenized, max_len_str)\n",
    "X_val_embed_matrix = text_to_matrix_using_word2vec(word_to_vec_model, x_val_text_tokenized, max_len_str)\n",
    "x_test_embed_matrix = text_to_matrix_using_word2vec(word_to_vec_model, x_test_text_tokenized, max_len_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "139a543f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abdelrahman/.local/lib/python3.6/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator LogisticRegression from version 1.0.2 when using version 0.23.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================== Validate Result =====================\n",
      "F1 score is:  0.4143387167175906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test using LogisticRegression \n",
    "\n",
    "model_path    = \"rezk/LogisticRegression__f1_0.41_ml.sav\"\n",
    "model = pickle_load_model(\"models/ml_models/\" + model_path)\n",
    "\n",
    "_ = train_val_test_score(model, X_train_embed_matrix, y_train, X_val_embed_matrix, y_val, \n",
    "                         x_test_embed_matrix, y_tes):"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
