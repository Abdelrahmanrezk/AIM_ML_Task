{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39058f6b",
   "metadata": {},
   "source": [
    "# Used Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "100296d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from typing import Optional\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "from fastapi.encoders import jsonable_encoder\n",
    "from fastapi import FastAPI\n",
    "from enum import Enum\n",
    "import os\n",
    "import io\n",
    "import pickle\n",
    "import uvicorn\n",
    "import nest_asyncio\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from data_shuffling_split import *\n",
    "from features_extraction import *\n",
    "from data_preprocess import *\n",
    "from ml_modeling import *\n",
    "from configs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d503bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abdelrahman/.local/lib/python3.6/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator LogisticRegression from version 1.0.2 when using version 0.23.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "number_of_features = 300\n",
    "max_len_str  = 64\n",
    "word2vec_path = \"rezk_unigram_CBOW_model/train_word2vec_cbow__window_3_min_count_300\"\n",
    "word_to_vec_model = load_word2vec_model(\"models/word2vec/\" + word2vec_path)\n",
    "\n",
    "model_path    = \"rezk/LogisticRegression__f1_0.41_ml.sav\"\n",
    "cls_model = pickle_load_model(\"models/ml_models/\" + model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6eca0c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dialect</th>\n",
       "      <th>dialect_l_encoded</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>521982921184251904</td>\n",
       "      <td>SA</td>\n",
       "      <td>13</td>\n",
       "      <td>ياكثرهم في زمانك وياقلهم في وفاك : ياما سمعنا ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>905803604950470784</td>\n",
       "      <td>BH</td>\n",
       "      <td>1</td>\n",
       "      <td>حسابشخصي انزين انت الحين ما عرفت التسعيره عشان...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>498984111034605568</td>\n",
       "      <td>LY</td>\n",
       "      <td>8</td>\n",
       "      <td>حسابشخصي ماعندكمش مطبخ في حوش فيه جو را 😂</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1119979622408556416</td>\n",
       "      <td>SY</td>\n",
       "      <td>15</td>\n",
       "      <td>حسابشخصي فصح مجيد وينعاد عليكي بالخير رابطويب</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1064139589617664000</td>\n",
       "      <td>KW</td>\n",
       "      <td>6</td>\n",
       "      <td>حسابشخصي الله يسلمج تسلمين وبزود نوركم وطيبكم ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id dialect  dialect_l_encoded  \\\n",
       "0   521982921184251904      SA                 13   \n",
       "1   905803604950470784      BH                  1   \n",
       "2   498984111034605568      LY                  8   \n",
       "3  1119979622408556416      SY                 15   \n",
       "4  1064139589617664000      KW                  6   \n",
       "\n",
       "                                                text  \n",
       "0  ياكثرهم في زمانك وياقلهم في وفاك : ياما سمعنا ...  \n",
       "1  حسابشخصي انزين انت الحين ما عرفت التسعيره عشان...  \n",
       "2         حسابشخصي ماعندكمش مطبخ في حوش فيه جو را 😂   \n",
       "3      حسابشخصي فصح مجيد وينعاد عليكي بالخير رابطويب  \n",
       "4  حسابشخصي الله يسلمج تسلمين وبزود نوركم وطيبكم ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strat_test_set = pd.read_csv(\"dataset/test/strat_test_set.csv\")\n",
    "strat_test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ddcaba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = list( strat_test_set['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7117f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_encoder = LabelEncoder()\n",
    "dialects  = list(strat_test_set[\"dialect\"])\n",
    "l_encoder.fit(dialects)\n",
    "len(l_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3c1c8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_text(text, model, word_to_vec_model=word_to_vec_model, max_len_str=max_len_str, cls_model=cls_model, l_encoder=l_encoder):\n",
    "    text_cleaned = clean_text(text['text'])\n",
    "    tokenized_text = tokenize_using_nltk_TreebankWordTokenizer([text_cleaned])\n",
    "    text_features = text_to_matrix_using_word2vec(word_to_vec_model, tokenized_text, max_len_str)\n",
    "    \n",
    "    predicted = text['predicted_class']\n",
    "    \n",
    "    # Check which model you need to predicit \n",
    "    if model == \"Machine Learning Model\":\n",
    "        print(\"=\"*50)\n",
    "        predicted = cls_model.predict(text_features)[0]\n",
    "    elif model == \"Deep Learning Model\":\n",
    "\n",
    "        print(\"=\"*50)\n",
    "        predicted = cls_model.predict(text_features)[0]\n",
    "        \n",
    "    \n",
    "    pred_result = l_encoder.inverse_transform([predicted])\n",
    "    \n",
    "    # Return dictionary\n",
    "    classifed_text = {\n",
    "        'text': text['text'],\n",
    "        'predicted_class': str(pred_result[0])\n",
    "    }\n",
    "    return classifed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44536980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign an instance of the FastAPI class to the variable \"app\".\n",
    "# You will interact with your api using this instance.\n",
    "app = FastAPI(title='Deploying a ML & DL Model with FastAPI')\n",
    "\n",
    "# List available models using Enum\n",
    "class Model(str, Enum):\n",
    "    ML_Model = \"Machine Learning Model\"\n",
    "    DL_Model = \"Deep Learning Model\"\n",
    "\n",
    "\n",
    "class Text(BaseModel):\n",
    "    text: str = \"\"\"ياكثرهم في زمانك وياقلهم في وفاك : ياما سمعنا القصايد لكنها ما تفيد العذر والغدر واضح تجني طريق الهلاك : اما حفظت المواصل والا خسرت الرصيد\"\"\"\n",
    "    predicted_class: str = 'SA'\n",
    "        \n",
    "\n",
    "@app.get(\"/\")\n",
    "def home():\n",
    "    # Once you go to this link you will see the get and post method below to trying out\n",
    "    return \"Congratulations! Your API is working as expected. Now head over to http://localhost:5000/docs.\"\n",
    "\n",
    "\n",
    "# This endpoint handles all the logic necessary for the object detection to work.\n",
    "# It requires the desired model and the dictionary of tweet and default class as we give default values to us\n",
    "# In the api you can try other tweet from some_tweets below\n",
    "@app.post(\"/predict\") \n",
    "def prediction(model: Model, text: Text):\n",
    "    \n",
    "    # Encode the retrived request data \n",
    "    text = jsonable_encoder(text)\n",
    "\n",
    "    # Run our model\n",
    "    classifed_text = classify_text(text, model)\n",
    "    \n",
    "    return classifed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095039d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [10453]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:5000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:44010 - \"GET /docs HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:44010 - \"GET /openapi.json HTTP/1.1\" 200 OK\n",
      "(1, 19200)\n",
      "==================================================\n",
      "[ 0.629     1.157    -0.6753    0.2048    0.2107    0.516    -0.6455\n",
      "  0.669    -0.72      1.04      0.2937   -0.4473   -0.2487    0.1098\n",
      " -0.1501    0.625     0.012115  0.2568   -1.126     0.2261   -0.08954\n",
      "  0.4692    0.1472    0.4668   -0.0946    0.3938    0.1757    0.413\n",
      " -0.189     0.03577  -0.816     0.8457   -0.3623   -0.564     0.619\n",
      "  0.3655    0.714    -0.3547    0.0713    1.005     0.594     0.671\n",
      "  0.7793    0.1586    0.2812   -0.11224  -0.7334    0.2106    0.4324\n",
      "  0.941   ]\n",
      "==================================================\n",
      "INFO:     127.0.0.1:44010 - \"POST /predict?model=Machine%20Learning%20Model HTTP/1.1\" 200 OK\n"
     ]
    }
   ],
   "source": [
    "# Allows the server to be run in this interactive environment\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Host depends on the setup you selected (docker or virtual env)\n",
    "host = \"0.0.0.0\" if os.getenv(\"DOCKER-SETUP\") else \"127.0.0.1\"\n",
    "\n",
    "# uvicorn is fast Asynchronous Server Gateway Interface (ASGI) uvicorn handles the serving\n",
    "# Spin up the server!    \n",
    "uvicorn.run(app, host=host, port=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f58cd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
