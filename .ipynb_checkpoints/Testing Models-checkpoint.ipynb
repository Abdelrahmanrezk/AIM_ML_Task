{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48964984",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from data_shuffling_split import *\n",
    "from features_extraction import *\n",
    "from data_preprocess import *\n",
    "from ml_modeling import *\n",
    "from configs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8495f97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dialect</th>\n",
       "      <th>dialect_l_encoded</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>521982921184251904</td>\n",
       "      <td>SA</td>\n",
       "      <td>13</td>\n",
       "      <td>ÙŠØ§ÙƒØ«Ø±Ù‡Ù… ÙÙŠ Ø²Ù…Ø§Ù†Ùƒ ÙˆÙŠØ§Ù‚Ù„Ù‡Ù… ÙÙŠ ÙˆÙØ§Ùƒ : ÙŠØ§Ù…Ø§ Ø³Ù…Ø¹Ù†Ø§ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>905803604950470784</td>\n",
       "      <td>BH</td>\n",
       "      <td>1</td>\n",
       "      <td>Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ Ø§Ù†Ø²ÙŠÙ† Ø§Ù†Øª Ø§Ù„Ø­ÙŠÙ† Ù…Ø§ Ø¹Ø±ÙØª Ø§Ù„ØªØ³Ø¹ÙŠØ±Ù‡ Ø¹Ø´Ø§Ù†...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>498984111034605568</td>\n",
       "      <td>LY</td>\n",
       "      <td>8</td>\n",
       "      <td>Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ Ù…Ø§Ø¹Ù†Ø¯ÙƒÙ…Ø´ Ù…Ø·Ø¨Ø® ÙÙŠ Ø­ÙˆØ´ ÙÙŠÙ‡ Ø¬Ùˆ Ø±Ø§ ğŸ˜‚</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1119979622408556416</td>\n",
       "      <td>SY</td>\n",
       "      <td>15</td>\n",
       "      <td>Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ ÙØµØ­ Ù…Ø¬ÙŠØ¯ ÙˆÙŠÙ†Ø¹Ø§Ø¯ Ø¹Ù„ÙŠÙƒÙŠ Ø¨Ø§Ù„Ø®ÙŠØ± Ø±Ø§Ø¨Ø·ÙˆÙŠØ¨</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1064139589617664000</td>\n",
       "      <td>KW</td>\n",
       "      <td>6</td>\n",
       "      <td>Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ Ø§Ù„Ù„Ù‡ ÙŠØ³Ù„Ù…Ø¬ ØªØ³Ù„Ù…ÙŠÙ† ÙˆØ¨Ø²ÙˆØ¯ Ù†ÙˆØ±ÙƒÙ… ÙˆØ·ÙŠØ¨ÙƒÙ… ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id dialect  dialect_l_encoded  \\\n",
       "0   521982921184251904      SA                 13   \n",
       "1   905803604950470784      BH                  1   \n",
       "2   498984111034605568      LY                  8   \n",
       "3  1119979622408556416      SY                 15   \n",
       "4  1064139589617664000      KW                  6   \n",
       "\n",
       "                                                text  \n",
       "0  ÙŠØ§ÙƒØ«Ø±Ù‡Ù… ÙÙŠ Ø²Ù…Ø§Ù†Ùƒ ÙˆÙŠØ§Ù‚Ù„Ù‡Ù… ÙÙŠ ÙˆÙØ§Ùƒ : ÙŠØ§Ù…Ø§ Ø³Ù…Ø¹Ù†Ø§ ...  \n",
       "1  Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ Ø§Ù†Ø²ÙŠÙ† Ø§Ù†Øª Ø§Ù„Ø­ÙŠÙ† Ù…Ø§ Ø¹Ø±ÙØª Ø§Ù„ØªØ³Ø¹ÙŠØ±Ù‡ Ø¹Ø´Ø§Ù†...  \n",
       "2         Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ Ù…Ø§Ø¹Ù†Ø¯ÙƒÙ…Ø´ Ù…Ø·Ø¨Ø® ÙÙŠ Ø­ÙˆØ´ ÙÙŠÙ‡ Ø¬Ùˆ Ø±Ø§ ğŸ˜‚   \n",
       "3      Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ ÙØµØ­ Ù…Ø¬ÙŠØ¯ ÙˆÙŠÙ†Ø¹Ø§Ø¯ Ø¹Ù„ÙŠÙƒÙŠ Ø¨Ø§Ù„Ø®ÙŠØ± Ø±Ø§Ø¨Ø·ÙˆÙŠØ¨  \n",
       "4  Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ Ø§Ù„Ù„Ù‡ ÙŠØ³Ù„Ù…Ø¬ ØªØ³Ù„Ù…ÙŠÙ† ÙˆØ¨Ø²ÙˆØ¯ Ù†ÙˆØ±ÙƒÙ… ÙˆØ·ÙŠØ¨ÙƒÙ… ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strat_test_set = pd.read_csv(\"dataset/test/strat_test_set.csv\")\n",
    "strat_test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebb5c2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_text, y_test = list(strat_test_set['text']), strat_test_set['dialect_l_encoded'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "216428e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Tokenization : \n",
      " ['ÙŠØ§ÙƒØ«Ø±Ù‡Ù… ÙÙŠ Ø²Ù…Ø§Ù†Ùƒ ÙˆÙŠØ§Ù‚Ù„Ù‡Ù… ÙÙŠ ÙˆÙØ§Ùƒ : ÙŠØ§Ù…Ø§ Ø³Ù…Ø¹Ù†Ø§ Ø§Ù„Ù‚ØµØ§ÙŠØ¯ Ù„ÙƒÙ†Ù‡Ø§ Ù…Ø§ ØªÙÙŠØ¯ Ø§Ù„Ø¹Ø°Ø± ÙˆØ§Ù„ØºØ¯Ø± ÙˆØ§Ø¶Ø­ ØªØ¬Ù†ÙŠ Ø·Ø±ÙŠÙ‚ Ø§Ù„Ù‡Ù„Ø§Ùƒ : Ø§Ù…Ø§ Ø­ÙØ¸Øª Ø§Ù„Ù…ÙˆØ§ØµÙ„ ÙˆØ§Ù„Ø§ Ø®Ø³Ø±Øª Ø§Ù„Ø±ØµÙŠØ¯', 'Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ Ø§Ù†Ø²ÙŠÙ† Ø§Ù†Øª Ø§Ù„Ø­ÙŠÙ† Ù…Ø§ Ø¹Ø±ÙØª Ø§Ù„ØªØ³Ø¹ÙŠØ±Ù‡ Ø¹Ø´Ø§Ù† ØªÙ‚ÙˆÙ„ Ù„Ù‡ go head Ø´Ù„ÙˆÙ† ØªØ¨ÙŠ Ø§Ù„Ø³ÙŠØ§Ø±Ù‡ ØªØ³ØªÙˆÙŠ ØŸ ', 'Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ Ù…Ø§Ø¹Ù†Ø¯ÙƒÙ…Ø´ Ù…Ø·Ø¨Ø® ÙÙŠ Ø­ÙˆØ´ ÙÙŠÙ‡ Ø¬Ùˆ Ø±Ø§ ğŸ˜‚ ']\n",
      "==================================================\n",
      "After Tokenization : \n",
      " [['ÙŠØ§ÙƒØ«Ø±Ù‡Ù…', 'ÙÙŠ', 'Ø²Ù…Ø§Ù†Ùƒ', 'ÙˆÙŠØ§Ù‚Ù„Ù‡Ù…', 'ÙÙŠ', 'ÙˆÙØ§Ùƒ', ':', 'ÙŠØ§Ù…Ø§', 'Ø³Ù…Ø¹Ù†Ø§', 'Ø§Ù„Ù‚ØµØ§ÙŠØ¯', 'Ù„ÙƒÙ†Ù‡Ø§', 'Ù…Ø§', 'ØªÙÙŠØ¯', 'Ø§Ù„Ø¹Ø°Ø±', 'ÙˆØ§Ù„ØºØ¯Ø±', 'ÙˆØ§Ø¶Ø­', 'ØªØ¬Ù†ÙŠ', 'Ø·Ø±ÙŠÙ‚', 'Ø§Ù„Ù‡Ù„Ø§Ùƒ', ':', 'Ø§Ù…Ø§', 'Ø­ÙØ¸Øª', 'Ø§Ù„Ù…ÙˆØ§ØµÙ„', 'ÙˆØ§Ù„Ø§', 'Ø®Ø³Ø±Øª', 'Ø§Ù„Ø±ØµÙŠØ¯'], ['Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ', 'Ø§Ù†Ø²ÙŠÙ†', 'Ø§Ù†Øª', 'Ø§Ù„Ø­ÙŠÙ†', 'Ù…Ø§', 'Ø¹Ø±ÙØª', 'Ø§Ù„ØªØ³Ø¹ÙŠØ±Ù‡', 'Ø¹Ø´Ø§Ù†', 'ØªÙ‚ÙˆÙ„', 'Ù„Ù‡', 'go', 'head', 'Ø´Ù„ÙˆÙ†', 'ØªØ¨ÙŠ', 'Ø§Ù„Ø³ÙŠØ§Ø±Ù‡', 'ØªØ³ØªÙˆÙŠ', 'ØŸ'], ['Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ', 'Ù…Ø§Ø¹Ù†Ø¯ÙƒÙ…Ø´', 'Ù…Ø·Ø¨Ø®', 'ÙÙŠ', 'Ø­ÙˆØ´', 'ÙÙŠÙ‡', 'Ø¬Ùˆ', 'Ø±Ø§', 'ğŸ˜‚']]\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "x_test_text_tokenized = tokenize_using_nltk_TreebankWordTokenizer(x_test_text)\n",
    "\n",
    "print(\"Before Tokenization : \\n\", x_test_text[:3])\n",
    "print(\"=\"*50)\n",
    "print(\"After Tokenization : \\n\", x_test_text_tokenized[:3])\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c8763d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_word2vec(x_test_embed_matrix, y_test, cls_model_path):\n",
    "    model = pickle_load_model(\"models/ml_models/\" + cls_model_path)\n",
    "    _ = f1_score_result(model, x_test_embed_matrix, y_test)\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "389fade5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9164, 6400)\n",
      "==================================================\n",
      "[-0.2822  -0.1575   3.271   -5.48    -0.6846   1.536    0.1155   0.1368\n",
      " -2.66    -2.887    0.4595   0.6196  -0.5166   0.4082   0.3364  -1.882\n",
      " -2.713   -2.545    0.4863   0.1699   0.01108  1.388   -2.156    2.8\n",
      " -2.316    1.119   -0.357   -0.5176  -0.3162   0.2896   1.391   -0.1215\n",
      " -0.7866   1.626    2.725   -0.8965   0.9175  -1.507   -1.036   -0.629\n",
      " -0.4058   0.0749   1.287    2.66    -1.376   -1.145    2.055   -0.1971\n",
      " -0.327   -3.309  ]\n"
     ]
    }
   ],
   "source": [
    "number_of_features = 100\n",
    "max_len_str  = 64\n",
    "\n",
    "word2vec_path = \"bakrianoo_unigram_cbow_model/full_uni_cbow_100_twitter.mdl\"\n",
    "word_to_vec_model = load_word2vec_model(\"models/word2vec/\" + word2vec_path)\n",
    "\n",
    "x_test_embed_matrix = text_to_matrix_using_word2vec(word_to_vec_model, x_test_text_tokenized, max_len_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef47eb0",
   "metadata": {},
   "source": [
    "# Using AboBakr Word2vec with AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb266721",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abdelrahman/.local/lib/python3.6/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator LinearSVC from version 1.0.2 when using version 0.23.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/abdelrahman/.local/lib/python3.6/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator AdaBoostClassifier from version 1.0.2 when using version 0.23.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================== Validate Result =====================\n",
      "F1 score is:  0.32802269751200347\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path    = \"bakr/AdaBoostClassifier__f1_0.325_ml.sav\"\n",
    "predict_with_word2vec(x_test_embed_matrix, y_test, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f0e1bb",
   "metadata": {},
   "source": [
    "# Using AboBakr Word2vec with Logistic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2145af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abdelrahman/.local/lib/python3.6/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator LogisticRegression from version 1.0.2 when using version 0.23.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================== Validate Result =====================\n",
      "F1 score is:  0.3644696639022261\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path    = \"bakr/unigram_100d_lg_cls_model_f1_0.366.sav\"\n",
    "predict_with_word2vec(x_test_embed_matrix, y_test, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148935f7",
   "metadata": {},
   "source": [
    "# Using Rezk Word2vec with AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6655ab86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9164, 19200)\n",
      "==================================================\n",
      "[ 0.629     1.157    -0.6753    0.2048    0.2107    0.516    -0.6455\n",
      "  0.669    -0.72      1.04      0.2937   -0.4473   -0.2487    0.1098\n",
      " -0.1501    0.625     0.012115  0.2568   -1.126     0.2261   -0.08954\n",
      "  0.4692    0.1472    0.4668   -0.0946    0.3938    0.1757    0.413\n",
      " -0.189     0.03577  -0.816     0.8457   -0.3623   -0.564     0.619\n",
      "  0.3655    0.714    -0.3547    0.0713    1.005     0.594     0.671\n",
      "  0.7793    0.1586    0.2812   -0.11224  -0.7334    0.2106    0.4324\n",
      "  0.941   ]\n"
     ]
    }
   ],
   "source": [
    "number_of_features = 300\n",
    "max_len_str  = 64\n",
    "\n",
    "word2vec_path = \"rezk_unigram_CBOW_model/train_word2vec_cbow__window_3_min_count_300\"\n",
    "word_to_vec_model = load_word2vec_model(\"models/word2vec/\" + word2vec_path)\n",
    "\n",
    "x_test_embed_matrix = text_to_matrix_using_word2vec(word_to_vec_model, x_test_text_tokenized, max_len_str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fd5a63",
   "metadata": {},
   "source": [
    "# Using Rezk Word2vec with Logistic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a02137e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abdelrahman/.local/lib/python3.6/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator LogisticRegression from version 1.0.2 when using version 0.23.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================== Validate Result =====================\n",
      "F1 score is:  0.4143387167175906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path    = \"rezk/LogisticRegression__f1_0.41_ml.sav\"\n",
    "predict_with_word2vec(x_test_embed_matrix, y_test, model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
