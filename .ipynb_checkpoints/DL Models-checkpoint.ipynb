{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b0f7203",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from configs import *\n",
    "from fetch_data import *\n",
    "from features_extraction import *\n",
    "from data_shuffling_split import *\n",
    "from data_preprocess import *\n",
    "from ml_modeling import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a47a22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances in the file are:  449033\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dialect</th>\n",
       "      <th>dialect_l_encoded</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1056552188082716800</td>\n",
       "      <td>LY</td>\n",
       "      <td>8</td>\n",
       "      <td>ุชูุง ุฏูุดู ุงูููุงุณููู ุดู ุจูุชููุง ูุดู ุจูุณูุชูู ูุดู ุจ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>891734969202114560</td>\n",
       "      <td>SY</td>\n",
       "      <td>15</td>\n",
       "      <td>ุญุณุงุจุดุฎุตู ูู ุงุญูู ูู ุงูุดุญุงุทู ๐</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1110565179257954432</td>\n",
       "      <td>SD</td>\n",
       "      <td>14</td>\n",
       "      <td>ุญุณุงุจุดุฎุตู ูููุจู ูุงููู ๐ ุงูุน ุชุญุงูู ุชุทูุฑูุง ุชููู ู...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1172817955270340608</td>\n",
       "      <td>LB</td>\n",
       "      <td>7</td>\n",
       "      <td>ุญุณุงุจุดุฎุตู ุญุณุงุจุดุฎุตู ๐ ุงูุง ุตุฑูู ุนุดุฑ ุณููู ูุด ูุฌุฏุฏู...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>293253217821790208</td>\n",
       "      <td>QA</td>\n",
       "      <td>12</td>\n",
       "      <td>ุงุญูู ุดุนูุฑ ุชููู ุจุงุฌุงุฒู ูุชููู ูู ุงูุตุจุญ ูุชูุฑ ุน ุงู...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id dialect  dialect_l_encoded  \\\n",
       "0  1056552188082716800      LY                  8   \n",
       "1   891734969202114560      SY                 15   \n",
       "2  1110565179257954432      SD                 14   \n",
       "3  1172817955270340608      LB                  7   \n",
       "4   293253217821790208      QA                 12   \n",
       "\n",
       "                                                text  \n",
       "0  ุชูุง ุฏูุดู ุงูููุงุณููู ุดู ุจูุชููุง ูุดู ุจูุณูุชูู ูุดู ุจ...  \n",
       "1                     ุญุณุงุจุดุฎุตู ูู ุงุญูู ูู ุงูุดุญุงุทู ๐   \n",
       "2  ุญุณุงุจุดุฎุตู ูููุจู ูุงููู ๐ ุงูุน ุชุญุงูู ุชุทูุฑูุง ุชููู ู...  \n",
       "3  ุญุณุงุจุดุฎุตู ุญุณุงุจุดุฎุตู ๐ ุงูุง ุตุฑูู ุนุดุฑ ุณููู ูุด ูุฌุฏุฏู...  \n",
       "4  ุงุญูู ุดุนูุฑ ุชููู ุจุงุฌุงุฒู ูุชููู ูู ุงูุตุจุญ ูุชูุฑ ุน ุงู...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strat_train_set = read_csv(\"train/strat_train_set.csv\")\n",
    "strat_train_set = strat_train_set.iloc[:5000]\n",
    "strat_train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05fee620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of instances in the training data after StratifiedShuffleSplit are:  4900\n",
      "The number of instances in the testing data after StratifiedShuffleSplit are:   100\n",
      "The number of trainin instances:  4900\n",
      "The number of validation instances:  100\n",
      "The number of trainin labels :  4900\n",
      "The number of validation labels :  100\n"
     ]
    }
   ],
   "source": [
    "x_train_text, x_val_text, y_train, y_val = prepare_data(strat_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f02c2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Tokenization : \n",
      " ['ุญุณุงุจุดุฎุตู ุญุณุงุจุดุฎุตู ๐ ุนููุง ููู ุงูุชูุช ุตูุงุญูุชู . . ุงุธุงูุฑ ุงูู ุดุงุฑุจ ุญุงุฌู', 'ุญุณุงุจุดุฎุตู ุงูุช ูุงุนูุฏู ุดุบู ุบูุฑ ุณุจ ูุดุชู ุฎูุงุต ุชุฑุงู ุงุจุซุฑุชูุง ุงูุช ูุงูู ุงููุทููู ุบูุท', 'ุญุณุงุจุดุฎุตู ุทุจ ุงุชูุฑุฌู ูุงูุชู ุณุงูุชู ๐ ']\n",
      "==================================================\n",
      "After Tokenization : \n",
      " [['ุญุณุงุจุดุฎุตู', 'ุญุณุงุจุดุฎุตู', '๐', 'ุนููุง', 'ููู', 'ุงูุชูุช', 'ุตูุงุญูุชู', '.', '.', 'ุงุธุงูุฑ', 'ุงูู', 'ุดุงุฑุจ', 'ุญุงุฌู'], ['ุญุณุงุจุดุฎุตู', 'ุงูุช', 'ูุงุนูุฏู', 'ุดุบู', 'ุบูุฑ', 'ุณุจ', 'ูุดุชู', 'ุฎูุงุต', 'ุชุฑุงู', 'ุงุจุซุฑุชูุง', 'ุงูุช', 'ูุงูู', 'ุงููุทููู', 'ุบูุท'], ['ุญุณุงุจุดุฎุตู', 'ุทุจ', 'ุงุชูุฑุฌู', 'ูุงูุชู', 'ุณุงูุชู', '๐']]\n",
      "==================================================\n",
      "Before Tokenization : \n",
      " ['ุญุณุงุจุดุฎุตู ุฌู ูุดุชูุงู ูุงูููุง ูุจููู ูุญุท ูุฌูู ูุงูุชูููู', 'ุนุฒูุฒุงุชู ูุชุงุจุนุงุชู ุงููุฎููุงุช . . ุงุณูุญูุง ูู ูุง ุฌูุชูู ุงูููู . . ุจุณ ูุงุฌุฆุชููู ูุงููู ุชุชุงุจุนููู ุจุตูุช . Cc . . ุงููุงุช ุงูุฏูุงูู', 'ุญุณุงุจุดุฎุตู ุญุณุงุจุดุฎุตู ุญุณุงุจุดุฎุตู ุญุณุงุจุดุฎุตู ุญุณุงุจุดุฎุตู ุฏุงู ูุงูููู ุนูู ุดุญู ูุดูุก ุงููุฏ ุจุชููู ุฏุงู ูุฐุง ูุจุฐู ุนู ููุงูู ุงูุง ุงุชููู ุจุณุณ ูุน ุงูุฎููุฌูู ูู ุงููุชูุตููู ุจุงูุฎููุฌ ููุณู ๐ ุฑุงุจุทููุจ']\n",
      "==================================================\n",
      "After Tokenization : \n",
      " [['ุญุณุงุจุดุฎุตู', 'ุฌู', 'ูุดุชูุงู', 'ูุงูููุง', 'ูุจููู', 'ูุญุท', 'ูุฌูู', 'ูุงูุชูููู'], ['ุนุฒูุฒุงุชู', 'ูุชุงุจุนุงุชู', 'ุงููุฎููุงุช', '.', '.', 'ุงุณูุญูุง', 'ูู', 'ูุง', 'ุฌูุชูู', 'ุงูููู', '.', '.', 'ุจุณ', 'ูุงุฌุฆุชููู', 'ูุงููู', 'ุชุชุงุจุนููู', 'ุจุตูุช', '.', 'Cc', '.', '.', 'ุงููุงุช', 'ุงูุฏูุงูู'], ['ุญุณุงุจุดุฎุตู', 'ุญุณุงุจุดุฎุตู', 'ุญุณุงุจุดุฎุตู', 'ุญุณุงุจุดุฎุตู', 'ุญุณุงุจุดุฎุตู', 'ุฏุงู', 'ูุงูููู', 'ุนูู', 'ุดุญู', 'ูุดูุก', 'ุงููุฏ', 'ุจุชููู', 'ุฏุงู', 'ูุฐุง', 'ูุจุฐู', 'ุนู', 'ููุงูู', 'ุงูุง', 'ุงุชููู', 'ุจุณุณ', 'ูุน', 'ุงูุฎููุฌูู', 'ูู', 'ุงููุชูุตููู', 'ุจุงูุฎููุฌ', 'ููุณู', '๐', 'ุฑุงุจุทููุจ']]\n"
     ]
    }
   ],
   "source": [
    "x_train_text_tokenized = tokenize_using_nltk_TreebankWordTokenizer(x_train_text)\n",
    "\n",
    "print(\"Before Tokenization : \\n\", x_train_text[:3])\n",
    "print(\"=\"*50)\n",
    "print(\"After Tokenization : \\n\", x_train_text_tokenized[:3])\n",
    "print(\"=\"*50)\n",
    "\n",
    "x_val_text_tokenized = tokenize_using_nltk_TreebankWordTokenizer(x_val_text)\n",
    "\n",
    "print(\"Before Tokenization : \\n\", x_val_text[:3])\n",
    "print(\"=\"*50)\n",
    "print(\"After Tokenization : \\n\", x_val_text_tokenized[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "babd171a",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_vec_model = load_word2vec_model(\"models/word2vec/rezk_unigram_CBOW_model/train_word2vec_cbow__window_3_min_count_300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e72ec00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ุญุณุงุจุดุฎุตู', 'ูู', 'ุฑุงุจุทููุจ', '#', 'ูู', ':', 'ุงููู', 'ุนูู', 'ูุง', '!']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = list(word_to_vec_model.wv.key_to_index)\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a9c9178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_vec_model.wv['ุงููู'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "015ff571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max length is:  71\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[13, 14, 6, 9, 7, 6, 29, 10, 12, 14]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get how many words inside each text after tokenization\n",
    "num_of_words_in_each_text = [len(text) for text in x_train_text_tokenized]\n",
    "max_len = max(num_of_words_in_each_text)\n",
    "print(\"The max length is: \", max_len)\n",
    "num_of_words_in_each_text[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "595d1349",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_features = 300\n",
    "max_len_str = max_len\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "\n",
    "X_train_embed_matrix = DL_text_to_matrix_using_word2vec(word_to_vec_model, x_train_text_tokenized)\n",
    "\n",
    "X_val_embed_matrix = DL_text_to_matrix_using_word2vec(word_to_vec_model, x_val_text_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "075a80a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77dac3d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4900, 71)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_embed_matrix = pad_sequences(X_train_embed_matrix, maxlen=max_len_str, padding='post')\n",
    "X_train_embed_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a0b5c5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 71)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_embed_matrix = pad_sequences(X_val_embed_matrix, maxlen=max_len_str, padding='post')\n",
    "X_val_embed_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71fd7d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f9bc49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nurons = 50\n",
    "model = Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53e7cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(SimpleRNN(\n",
    "    num_nurons, \n",
    "    return_sequences=True,\n",
    "    input_shape=(max_len_str, number_of_features)\n",
    "))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Flatten())\n",
    "model.add(18, activation=\"softmax\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
