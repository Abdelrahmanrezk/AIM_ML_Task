{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b0f7203",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from configs import *\n",
    "from fetch_data import *\n",
    "from features_extraction import *\n",
    "from data_shuffling_split import *\n",
    "from data_preprocess import *\n",
    "from ml_modeling import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a47a22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances in the file are:  449033\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dialect</th>\n",
       "      <th>dialect_l_encoded</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1056552188082716800</td>\n",
       "      <td>LY</td>\n",
       "      <td>8</td>\n",
       "      <td>ØªÙˆØ§ Ø¯ÙˆØ´Ù‡ Ø§Ù„ÙƒÙ„Ø§Ø³ÙŠÙƒÙˆ Ø´Ù† Ø¨ÙŠØªÙ…Ù‡Ø§ ÙˆØ´Ù† Ø¨ÙŠØ³ÙƒØªÙ‡Ù… ÙˆØ´Ù† Ø¨...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>891734969202114560</td>\n",
       "      <td>SY</td>\n",
       "      <td>15</td>\n",
       "      <td>Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ ÙÙŠ Ø§Ø­Ù„ÙŠ Ù…Ù† Ø§Ù„Ø´Ø­Ø§Ø·Ù‡ ğŸ˜‚</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1110565179257954432</td>\n",
       "      <td>SD</td>\n",
       "      <td>14</td>\n",
       "      <td>Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ Ù…ÙˆÙ‡Ø¨Ù‡ ÙˆØ§Ù„Ù„Ù‡ ğŸ˜‚ Ø§ÙˆØ¹ ØªØ­Ø§ÙˆÙ„ ØªØ·ÙˆØ±Ù‡Ø§ ØªÙ‚ÙˆÙ… Ù…...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1172817955270340608</td>\n",
       "      <td>LB</td>\n",
       "      <td>7</td>\n",
       "      <td>Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ ğŸ˜‚ Ø§Ù†Ø§ ØµØ±Ù„ÙŠ Ø¹Ø´Ø± Ø³Ù†ÙŠÙ† Ù…Ø´ Ù…Ø¬Ø¯Ø¯Ù‡...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>293253217821790208</td>\n",
       "      <td>QA</td>\n",
       "      <td>12</td>\n",
       "      <td>Ø§Ø­Ù„ÙŠ Ø´Ø¹ÙˆØ± ØªÙƒÙˆÙ† Ø¨Ø§Ø¬Ø§Ø²Ù‡ ÙˆØªÙ‚ÙˆÙ… Ù…Ù† Ø§Ù„ØµØ¨Ø­ ÙˆØªÙ…Ø± Ø¹ Ø§Ù„...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id dialect  dialect_l_encoded  \\\n",
       "0  1056552188082716800      LY                  8   \n",
       "1   891734969202114560      SY                 15   \n",
       "2  1110565179257954432      SD                 14   \n",
       "3  1172817955270340608      LB                  7   \n",
       "4   293253217821790208      QA                 12   \n",
       "\n",
       "                                                text  \n",
       "0  ØªÙˆØ§ Ø¯ÙˆØ´Ù‡ Ø§Ù„ÙƒÙ„Ø§Ø³ÙŠÙƒÙˆ Ø´Ù† Ø¨ÙŠØªÙ…Ù‡Ø§ ÙˆØ´Ù† Ø¨ÙŠØ³ÙƒØªÙ‡Ù… ÙˆØ´Ù† Ø¨...  \n",
       "1                     Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ ÙÙŠ Ø§Ø­Ù„ÙŠ Ù…Ù† Ø§Ù„Ø´Ø­Ø§Ø·Ù‡ ğŸ˜‚   \n",
       "2  Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ Ù…ÙˆÙ‡Ø¨Ù‡ ÙˆØ§Ù„Ù„Ù‡ ğŸ˜‚ Ø§ÙˆØ¹ ØªØ­Ø§ÙˆÙ„ ØªØ·ÙˆØ±Ù‡Ø§ ØªÙ‚ÙˆÙ… Ù…...  \n",
       "3  Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ ğŸ˜‚ Ø§Ù†Ø§ ØµØ±Ù„ÙŠ Ø¹Ø´Ø± Ø³Ù†ÙŠÙ† Ù…Ø´ Ù…Ø¬Ø¯Ø¯Ù‡...  \n",
       "4  Ø§Ø­Ù„ÙŠ Ø´Ø¹ÙˆØ± ØªÙƒÙˆÙ† Ø¨Ø§Ø¬Ø§Ø²Ù‡ ÙˆØªÙ‚ÙˆÙ… Ù…Ù† Ø§Ù„ØµØ¨Ø­ ÙˆØªÙ…Ø± Ø¹ Ø§Ù„...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strat_train_set = read_csv(\"train/strat_train_set.csv\")\n",
    "strat_train_set = strat_train_set.iloc[:5000]\n",
    "strat_train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05fee620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of instances in the training data after StratifiedShuffleSplit are:  4900\n",
      "The number of instances in the testing data after StratifiedShuffleSplit are:   100\n",
      "The number of trainin instances:  4900\n",
      "The number of validation instances:  100\n",
      "The number of trainin labels :  4900\n",
      "The number of validation labels :  100\n"
     ]
    }
   ],
   "source": [
    "x_train_text, x_val_text, y_train, y_val = prepare_data(strat_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f02c2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Tokenization : \n",
      " ['Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ ğŸ˜‚ Ø¹ÙÙˆØ§ Ù…ÙŠÙ† Ø§Ù†ØªÙ‡Øª ØµÙ„Ø§Ø­ÙŠØªÙ‡ . . Ø§Ø¸Ø§Ù‡Ø± Ø§Ù†Ùƒ Ø´Ø§Ø±Ø¨ Ø­Ø§Ø¬Ù‡', 'Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ Ø§Ù†Øª Ù…Ø§Ø¹Ù†Ø¯Ùƒ Ø´ØºÙ„ ØºÙŠØ± Ø³Ø¨ ÙˆØ´ØªÙ… Ø®Ù„Ø§Øµ ØªØ±Ø§Ùƒ Ø§Ø¨Ø«Ø±ØªÙ†Ø§ Ø§Ù†Øª ÙØ§Ù‡Ù… Ø§Ù„ÙˆØ·Ù†ÙŠÙ‡ ØºÙ„Ø·', 'Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ Ø·Ø¨ Ø§ØªÙØ±Ø¬ÙŠ ÙˆØ§Ù†ØªÙŠ Ø³Ø§ÙƒØªÙ‡ ğŸ˜‚ ']\n",
      "==================================================\n",
      "After Tokenization : \n",
      " [['Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ', 'Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ', 'ğŸ˜‚', 'Ø¹ÙÙˆØ§', 'Ù…ÙŠÙ†', 'Ø§Ù†ØªÙ‡Øª', 'ØµÙ„Ø§Ø­ÙŠØªÙ‡', '.', '.', 'Ø§Ø¸Ø§Ù‡Ø±', 'Ø§Ù†Ùƒ', 'Ø´Ø§Ø±Ø¨', 'Ø­Ø§Ø¬Ù‡'], ['Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ', 'Ø§Ù†Øª', 'Ù…Ø§Ø¹Ù†Ø¯Ùƒ', 'Ø´ØºÙ„', 'ØºÙŠØ±', 'Ø³Ø¨', 'ÙˆØ´ØªÙ…', 'Ø®Ù„Ø§Øµ', 'ØªØ±Ø§Ùƒ', 'Ø§Ø¨Ø«Ø±ØªÙ†Ø§', 'Ø§Ù†Øª', 'ÙØ§Ù‡Ù…', 'Ø§Ù„ÙˆØ·Ù†ÙŠÙ‡', 'ØºÙ„Ø·'], ['Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ', 'Ø·Ø¨', 'Ø§ØªÙØ±Ø¬ÙŠ', 'ÙˆØ§Ù†ØªÙŠ', 'Ø³Ø§ÙƒØªÙ‡', 'ğŸ˜‚']]\n",
      "==================================================\n",
      "Before Tokenization : \n",
      " ['Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ Ø¬Ùˆ Ù…Ø´ØªÙ…Ø§Ù… ÙŠØ§Ù‡ÙŠÙ…Ø§ ÙŠØ¨ÙˆÙ†ÙŠ Ù†Ø­Ø· Ù†Ø¬ÙˆÙ… ÙØ§Ù„ØªÙÙ„ÙŠÙ…', 'Ø¹Ø²ÙŠØ²Ø§ØªÙŠ Ù…ØªØ§Ø¨Ø¹Ø§ØªÙŠ Ø§Ù„Ù…Ø®ÙÙŠØ§Øª . . Ø§Ø³Ù…Ø­ÙˆØ§ Ù„ÙŠ Ù…Ø§ Ø¬ÙŠØªÙƒÙ… Ø§Ù„ÙŠÙˆÙ… . . Ø¨Ø³ ÙØ§Ø¬Ø¦ØªÙˆÙ†ÙŠ ÙŠØ§Ù„Ù„ÙŠ ØªØªØ§Ø¨Ø¹ÙˆÙ†ÙŠ Ø¨ØµÙ…Øª . Cc . . Ø§Ù…Ù‡Ø§Øª Ø§Ù„Ø¯ÙˆØ§Ù‡ÙŠ', 'Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ Ø¯Ø§Ù… Ù…Ø§ÙŠÙ‡Ù…Ùƒ Ø¹Ù„ÙŠ Ø´Ø­Ù… ÙˆØ´ÙŠØ¡ Ø§ÙƒÙŠØ¯ Ø¨ØªÙƒÙ„Ù… Ø¯Ø§Ù… Ù‡Ø°Ø§ Ù†Ø¨Ø°Ù‡ Ø¹Ù† ÙƒÙ„Ø§Ù…Ùƒ Ø§Ù†Ø§ Ø§ØªÙƒÙ„Ù… Ø¨Ø³Ø³ Ù…Ø¹ Ø§Ù„Ø®Ù„ÙŠØ¬ÙŠÙ† Ù…Ùˆ Ø§Ù„Ù…ØªÙ„ØµÙ‚ÙŠÙ† Ø¨Ø§Ù„Ø®Ù„ÙŠØ¬ Ù†ÙØ³Ùƒ ğŸ˜‚ Ø±Ø§Ø¨Ø·ÙˆÙŠØ¨']\n",
      "==================================================\n",
      "After Tokenization : \n",
      " [['Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ', 'Ø¬Ùˆ', 'Ù…Ø´ØªÙ…Ø§Ù…', 'ÙŠØ§Ù‡ÙŠÙ…Ø§', 'ÙŠØ¨ÙˆÙ†ÙŠ', 'Ù†Ø­Ø·', 'Ù†Ø¬ÙˆÙ…', 'ÙØ§Ù„ØªÙÙ„ÙŠÙ…'], ['Ø¹Ø²ÙŠØ²Ø§ØªÙŠ', 'Ù…ØªØ§Ø¨Ø¹Ø§ØªÙŠ', 'Ø§Ù„Ù…Ø®ÙÙŠØ§Øª', '.', '.', 'Ø§Ø³Ù…Ø­ÙˆØ§', 'Ù„ÙŠ', 'Ù…Ø§', 'Ø¬ÙŠØªÙƒÙ…', 'Ø§Ù„ÙŠÙˆÙ…', '.', '.', 'Ø¨Ø³', 'ÙØ§Ø¬Ø¦ØªÙˆÙ†ÙŠ', 'ÙŠØ§Ù„Ù„ÙŠ', 'ØªØªØ§Ø¨Ø¹ÙˆÙ†ÙŠ', 'Ø¨ØµÙ…Øª', '.', 'Cc', '.', '.', 'Ø§Ù…Ù‡Ø§Øª', 'Ø§Ù„Ø¯ÙˆØ§Ù‡ÙŠ'], ['Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ', 'Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ', 'Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ', 'Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ', 'Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ', 'Ø¯Ø§Ù…', 'Ù…Ø§ÙŠÙ‡Ù…Ùƒ', 'Ø¹Ù„ÙŠ', 'Ø´Ø­Ù…', 'ÙˆØ´ÙŠØ¡', 'Ø§ÙƒÙŠØ¯', 'Ø¨ØªÙƒÙ„Ù…', 'Ø¯Ø§Ù…', 'Ù‡Ø°Ø§', 'Ù†Ø¨Ø°Ù‡', 'Ø¹Ù†', 'ÙƒÙ„Ø§Ù…Ùƒ', 'Ø§Ù†Ø§', 'Ø§ØªÙƒÙ„Ù…', 'Ø¨Ø³Ø³', 'Ù…Ø¹', 'Ø§Ù„Ø®Ù„ÙŠØ¬ÙŠÙ†', 'Ù…Ùˆ', 'Ø§Ù„Ù…ØªÙ„ØµÙ‚ÙŠÙ†', 'Ø¨Ø§Ù„Ø®Ù„ÙŠØ¬', 'Ù†ÙØ³Ùƒ', 'ğŸ˜‚', 'Ø±Ø§Ø¨Ø·ÙˆÙŠØ¨']]\n"
     ]
    }
   ],
   "source": [
    "x_train_text_tokenized = tokenize_using_nltk_TreebankWordTokenizer(x_train_text)\n",
    "\n",
    "print(\"Before Tokenization : \\n\", x_train_text[:3])\n",
    "print(\"=\"*50)\n",
    "print(\"After Tokenization : \\n\", x_train_text_tokenized[:3])\n",
    "print(\"=\"*50)\n",
    "\n",
    "x_val_text_tokenized = tokenize_using_nltk_TreebankWordTokenizer(x_val_text)\n",
    "\n",
    "print(\"Before Tokenization : \\n\", x_val_text[:3])\n",
    "print(\"=\"*50)\n",
    "print(\"After Tokenization : \\n\", x_val_text_tokenized[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "babd171a",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_vec_model = load_word2vec_model(\"models/word2vec/rezk_unigram_CBOW_model/train_word2vec_cbow__window_3_min_count_300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e72ec00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ', 'Ù…Ù†', 'Ø±Ø§Ø¨Ø·ÙˆÙŠØ¨', '#', 'ÙÙŠ', ':', 'Ø§Ù„Ù„Ù‡', 'Ø¹Ù„ÙŠ', 'Ù„Ø§', '!']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = list(word_to_vec_model.wv.key_to_index)\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a9c9178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_vec_model.wv['Ø§Ù„Ù„Ù‡'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "015ff571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max length is:  71\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[13, 14, 6, 9, 7, 6, 29, 10, 12, 14]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get how many words inside each text after tokenization\n",
    "num_of_words_in_each_text = [len(text) for text in x_train_text_tokenized]\n",
    "max_len = max(num_of_words_in_each_text)\n",
    "print(\"The max length is: \", max_len)\n",
    "num_of_words_in_each_text[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "595d1349",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_features = 300\n",
    "max_len_str = max_len\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "\n",
    "X_train_embed_matrix = DL_text_to_matrix_using_word2vec(word_to_vec_model, x_train_text_tokenized)\n",
    "\n",
    "X_val_embed_matrix = DL_text_to_matrix_using_word2vec(word_to_vec_model, x_val_text_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "075a80a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77dac3d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4900, 71)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_embed_matrix = pad_sequences(X_train_embed_matrix, maxlen=max_len_str, padding='post')\n",
    "X_train_embed_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a0b5c5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 71)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_embed_matrix = pad_sequences(X_val_embed_matrix, maxlen=max_len_str, padding='post')\n",
    "X_val_embed_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71fd7d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f9bc49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nurons = 50\n",
    "model = Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53e7cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(SimpleRNN(\n",
    "    num_nurons, \n",
    "    return_sequences=True,\n",
    "    input_shape=(max_len_str, number_of_features)\n",
    "))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Flatten())\n",
    "model.add(18, activation=\"softmax\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
