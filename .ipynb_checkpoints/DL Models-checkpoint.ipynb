{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2595a258",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, LSTM, Embedding\n",
    "from configs import *\n",
    "from fetch_data import *\n",
    "from features_extraction import *\n",
    "from data_shuffling_split import *\n",
    "from data_preprocess import *\n",
    "from ml_modeling import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8deed7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances in the file are:  449033\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dialect</th>\n",
       "      <th>dialect_l_encoded</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1056552188082716800</td>\n",
       "      <td>LY</td>\n",
       "      <td>8</td>\n",
       "      <td>ØªÙˆØ§ Ø¯ÙˆØ´Ù‡ Ø§Ù„ÙƒÙ„Ø§Ø³ÙŠÙƒÙˆ Ø´Ù† Ø¨ÙŠØªÙ…Ù‡Ø§ ÙˆØ´Ù† Ø¨ÙŠØ³ÙƒØªÙ‡Ù… ÙˆØ´Ù† Ø¨...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>891734969202114560</td>\n",
       "      <td>SY</td>\n",
       "      <td>15</td>\n",
       "      <td>Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ ÙÙŠ Ø§Ø­Ù„ÙŠ Ù…Ù† Ø§Ù„Ø´Ø­Ø§Ø·Ù‡ ğŸ˜‚</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1110565179257954432</td>\n",
       "      <td>SD</td>\n",
       "      <td>14</td>\n",
       "      <td>Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ Ù…ÙˆÙ‡Ø¨Ù‡ ÙˆØ§Ù„Ù„Ù‡ ğŸ˜‚ Ø§ÙˆØ¹ ØªØ­Ø§ÙˆÙ„ ØªØ·ÙˆØ±Ù‡Ø§ ØªÙ‚ÙˆÙ… Ù…...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1172817955270340608</td>\n",
       "      <td>LB</td>\n",
       "      <td>7</td>\n",
       "      <td>Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ ğŸ˜‚ Ø§Ù†Ø§ ØµØ±Ù„ÙŠ Ø¹Ø´Ø± Ø³Ù†ÙŠÙ† Ù…Ø´ Ù…Ø¬Ø¯Ø¯Ù‡...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>293253217821790208</td>\n",
       "      <td>QA</td>\n",
       "      <td>12</td>\n",
       "      <td>Ø§Ø­Ù„ÙŠ Ø´Ø¹ÙˆØ± ØªÙƒÙˆÙ† Ø¨Ø§Ø¬Ø§Ø²Ù‡ ÙˆØªÙ‚ÙˆÙ… Ù…Ù† Ø§Ù„ØµØ¨Ø­ ÙˆØªÙ…Ø± Ø¹ Ø§Ù„...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id dialect  dialect_l_encoded  \\\n",
       "0  1056552188082716800      LY                  8   \n",
       "1   891734969202114560      SY                 15   \n",
       "2  1110565179257954432      SD                 14   \n",
       "3  1172817955270340608      LB                  7   \n",
       "4   293253217821790208      QA                 12   \n",
       "\n",
       "                                                text  \n",
       "0  ØªÙˆØ§ Ø¯ÙˆØ´Ù‡ Ø§Ù„ÙƒÙ„Ø§Ø³ÙŠÙƒÙˆ Ø´Ù† Ø¨ÙŠØªÙ…Ù‡Ø§ ÙˆØ´Ù† Ø¨ÙŠØ³ÙƒØªÙ‡Ù… ÙˆØ´Ù† Ø¨...  \n",
       "1                     Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ ÙÙŠ Ø§Ø­Ù„ÙŠ Ù…Ù† Ø§Ù„Ø´Ø­Ø§Ø·Ù‡ ğŸ˜‚   \n",
       "2  Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ Ù…ÙˆÙ‡Ø¨Ù‡ ÙˆØ§Ù„Ù„Ù‡ ğŸ˜‚ Ø§ÙˆØ¹ ØªØ­Ø§ÙˆÙ„ ØªØ·ÙˆØ±Ù‡Ø§ ØªÙ‚ÙˆÙ… Ù…...  \n",
       "3  Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ ğŸ˜‚ Ø§Ù†Ø§ ØµØ±Ù„ÙŠ Ø¹Ø´Ø± Ø³Ù†ÙŠÙ† Ù…Ø´ Ù…Ø¬Ø¯Ø¯Ù‡...  \n",
       "4  Ø§Ø­Ù„ÙŠ Ø´Ø¹ÙˆØ± ØªÙƒÙˆÙ† Ø¨Ø§Ø¬Ø§Ø²Ù‡ ÙˆØªÙ‚ÙˆÙ… Ù…Ù† Ø§Ù„ØµØ¨Ø­ ÙˆØªÙ…Ø± Ø¹ Ø§Ù„...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strat_train_set = read_csv(\"train/strat_train_set.csv\")\n",
    "strat_train_set = strat_train_set.iloc[:5000]\n",
    "strat_train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df9dd098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of instances in the training data after StratifiedShuffleSplit are:  4900\n",
      "The number of instances in the testing data after StratifiedShuffleSplit are:   100\n",
      "The number of trainin instances:  4900\n",
      "The number of validation instances:  100\n",
      "The number of trainin labels :  4900\n",
      "The number of validation labels :  100\n"
     ]
    }
   ],
   "source": [
    "x_train_text, x_val_text, y_train, y_val = prepare_data(strat_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0507dbfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Tokenization : \n",
      " ['Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ Ù…Ù„Ø¹ÙˆÙ† Ø§Ø¨ÙˆÙƒ ÙŠØ§ ÙÙ‚Ø± ÙŠØ§ Ø­Ø§ÙˆØ¬Ù†ÙŠ Ù„Ù„Ø§Ù†Ø¯Ø§Ù„ Ø°Ù„ÙŠØª Ø¹Ø²ÙŠØ² Ø§Ù„Ù†ÙØ³ Ø¹Ø´Ø§Ù† Ø¹Ø¯ÙŠÙ… Ø§Ù„Ù…Ø§Ù„', 'Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ ÙŠØ§Ù„Ù„Ù‡ ÙŠØ§Ù„Ù„Ù‡ ÙŠØ§Ù„Ù„Ù‡ ÙŠØ§ ÙƒØ±ÙŠÙ… Ø³Ø¨Ø­Ø§Ù†Ùƒ', 'Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ Ø¶Ø±ÙˆØ±ÙŠ ÙŠØ§ Ø²ÙˆÙ„ ØªØ¶Ù„ Ù…ÙˆØ¬ÙˆØ¯']\n",
      "==================================================\n",
      "After Tokenization : \n",
      " [['Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ', 'Ù…Ù„Ø¹ÙˆÙ†', 'Ø§Ø¨ÙˆÙƒ', 'ÙŠØ§', 'ÙÙ‚Ø±', 'ÙŠØ§', 'Ø­Ø§ÙˆØ¬Ù†ÙŠ', 'Ù„Ù„Ø§Ù†Ø¯Ø§Ù„', 'Ø°Ù„ÙŠØª', 'Ø¹Ø²ÙŠØ²', 'Ø§Ù„Ù†ÙØ³', 'Ø¹Ø´Ø§Ù†', 'Ø¹Ø¯ÙŠÙ…', 'Ø§Ù„Ù…Ø§Ù„'], ['Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ', 'ÙŠØ§Ù„Ù„Ù‡', 'ÙŠØ§Ù„Ù„Ù‡', 'ÙŠØ§Ù„Ù„Ù‡', 'ÙŠØ§', 'ÙƒØ±ÙŠÙ…', 'Ø³Ø¨Ø­Ø§Ù†Ùƒ'], ['Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ', 'Ø¶Ø±ÙˆØ±ÙŠ', 'ÙŠØ§', 'Ø²ÙˆÙ„', 'ØªØ¶Ù„', 'Ù…ÙˆØ¬ÙˆØ¯']]\n",
      "==================================================\n",
      "Before Tokenization : \n",
      " ['ØªØ±ÙŠ Ø­ØªÙŠ Ù„Ùˆ ÙƒØ§Ù† Ø¨ÙŠØ§Ø¹ Ø§Ù„Ø±Ù‚ÙŠ Ø¨Ù†Ø¸Ø±Ùƒ ÙŠØ¨ÙŠ ÙŠÙƒØ³Ø¨ ØªØ¹Ø§Ø·Ù Ø§Ù„Ù†Ø§Ø³ Ø¹Ø´Ø§Ù† ÙŠØ¹Ø·ÙˆÙ†Ù‡ ÙÙ„ÙˆØ³ Ø¹Ø´Ø§Ù† Ø¬Ø°ÙŠ Ø­Ø§Ø· Ø¬Ù… Ø±Ù‚ÙŠÙ‡ ÙˆÙŠØ¨Ø¹ Ù‡Ù… Ø§Ø¨Ø±Ùƒ Ù…Ù† Ù‚Ø¹Ø¯ØªÙ‡ Ø¨Ø§Ù„Ø¨ÙŠØª ÙˆØ¹Ù„ÙŠ Ø§Ù„Ø§Ù‚Ù„ Ø¹Ù†Ø¯Ù‡ ÙƒØ±Ø§Ù…Ù‡ ÙˆÙŠØ¨ÙŠ ÙŠØ¹ÙŠØ´ ÙˆÙŠØ¹ÙŠØ´ Ø§Ù‡Ù„Ù‡ . . Ø§Ù„Ø±Ø­Ù…Ù‡ ÙŠØ§ Ø¨Ø´Ø± ÙÙŠ Ø§ÙŠØ§Ù… Ø§Ù„Ø®ÙŠØ± #Ø¨ÙŠØ§Ø¹_Ø§Ù„Ø±Ù‚ÙŠ_Ø§Ù„Ø´Ø±ÙŠÙ', 'Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ Ø¹Ù† Ø§Ø¨ÙˆÙ‡ Ù…Ø§ ØªØ¨ØºÙˆÙ† Ø­ØªÙŠ ÙŠÙƒØ±Ù…ÙˆÙ† Ø¬Ù…Ø§Ù‡ÙŠØ±Ù‡Ù… Ø§Ù„Ù„ÙŠ Ø·ÙˆÙ„ Ø§Ù„ÙˆÙ‚Øª ÙÙŠ Ø§Ù„Ù†Ø§Ø¯ÙŠ ÙˆÙŠØ±Ø§ÙƒØ¶ÙˆÙ† ÙˆÙŠØ§Ù‡Ù… Ù…Ù† Ù†Ø§Ø¯ÙŠ Ù„Ù†Ø§Ø¯ÙŠ ÙˆÙŠØ´Ø¬Ø¹ÙˆÙ†Ù‡Ù… Ø·ÙˆÙ„ Ø§Ù„ÙˆÙ‚Øª . . . . . Ø§Ù„Ù„Ø§Ø¹Ø¨ Ø§Ø°Ø§ Ø­ØµÙ„ Ø¹Ø±Ø¶ Ø¨ÙŠØ±ÙˆØ­ Ù„ÙƒÙ† Ø§Ù„Ù…Ø´Ø¬Ø¹ Ø¨Ø§Ù‚ÙŠ Ø¨ÙŠØ¨ Ù„ÙƒÙ… Ø¬Ù…Ø§Ù‡ÙŠØ± ÙˆÙ„Ø§Ø¹Ø¨ÙŠÙ† ÙŠÙ„Ø¹Ø¨ÙˆÙ† ÙÙŠ Ø§Ù„Ù…Ø±Ø§Ø­Ù„ . . . . . ÙˆÙ…Ø³ØªÙƒØ«Ø± Ø¹Ù„ÙŠ Ù‡Ø°Ø§ Ø§Ù„Ù…Ø´Ø¬Ø¹ ÙˆÙ„Ø¯ Ø§Ù„Ù†Ø§Ø¯ÙŠ Ø§Ù„Ù„ÙŠ Ù…Ø§ Ø§Ø¹Ø±ÙÙ‡ ÙˆÙ„Ø§ Ø§Ø¹Ø±Ù Ù†Ø§Ø¯ÙŠÙ‡ Ø§Ù†Ù‡Ù… ÙŠÙˆØ¯ÙˆÙ†Ù‡', 'Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ Ø§Ù„Ù„Ù‡ ÙŠØ³Ù„Ù…Ùƒ ÙŠØ§Ø¨Ùˆ Ø¹Ø²ÙˆØ² ÙˆØ§Ø¨Ø´Ø±Ùƒ Ø·ÙŠØ¨ Ù„ÙƒÙ† Ø°Ø¨Ø­Ù†Ø§ Ø§Ù„Ø¨Ø±Ø¯ ÙÙŠ ÙØ±Ø§Ù†ÙƒÙÙˆØ±Øª . . ']\n",
      "==================================================\n",
      "After Tokenization : \n",
      " [['ØªØ±ÙŠ', 'Ø­ØªÙŠ', 'Ù„Ùˆ', 'ÙƒØ§Ù†', 'Ø¨ÙŠØ§Ø¹', 'Ø§Ù„Ø±Ù‚ÙŠ', 'Ø¨Ù†Ø¸Ø±Ùƒ', 'ÙŠØ¨ÙŠ', 'ÙŠÙƒØ³Ø¨', 'ØªØ¹Ø§Ø·Ù', 'Ø§Ù„Ù†Ø§Ø³', 'Ø¹Ø´Ø§Ù†', 'ÙŠØ¹Ø·ÙˆÙ†Ù‡', 'ÙÙ„ÙˆØ³', 'Ø¹Ø´Ø§Ù†', 'Ø¬Ø°ÙŠ', 'Ø­Ø§Ø·', 'Ø¬Ù…', 'Ø±Ù‚ÙŠÙ‡', 'ÙˆÙŠØ¨Ø¹', 'Ù‡Ù…', 'Ø§Ø¨Ø±Ùƒ', 'Ù…Ù†', 'Ù‚Ø¹Ø¯ØªÙ‡', 'Ø¨Ø§Ù„Ø¨ÙŠØª', 'ÙˆØ¹Ù„ÙŠ', 'Ø§Ù„Ø§Ù‚Ù„', 'Ø¹Ù†Ø¯Ù‡', 'ÙƒØ±Ø§Ù…Ù‡', 'ÙˆÙŠØ¨ÙŠ', 'ÙŠØ¹ÙŠØ´', 'ÙˆÙŠØ¹ÙŠØ´', 'Ø§Ù‡Ù„Ù‡', '.', '.', 'Ø§Ù„Ø±Ø­Ù…Ù‡', 'ÙŠØ§', 'Ø¨Ø´Ø±', 'ÙÙŠ', 'Ø§ÙŠØ§Ù…', 'Ø§Ù„Ø®ÙŠØ±', '#', 'Ø¨ÙŠØ§Ø¹_Ø§Ù„Ø±Ù‚ÙŠ_Ø§Ù„Ø´Ø±ÙŠÙ'], ['Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ', 'Ø¹Ù†', 'Ø§Ø¨ÙˆÙ‡', 'Ù…Ø§', 'ØªØ¨ØºÙˆÙ†', 'Ø­ØªÙŠ', 'ÙŠÙƒØ±Ù…ÙˆÙ†', 'Ø¬Ù…Ø§Ù‡ÙŠØ±Ù‡Ù…', 'Ø§Ù„Ù„ÙŠ', 'Ø·ÙˆÙ„', 'Ø§Ù„ÙˆÙ‚Øª', 'ÙÙŠ', 'Ø§Ù„Ù†Ø§Ø¯ÙŠ', 'ÙˆÙŠØ±Ø§ÙƒØ¶ÙˆÙ†', 'ÙˆÙŠØ§Ù‡Ù…', 'Ù…Ù†', 'Ù†Ø§Ø¯ÙŠ', 'Ù„Ù†Ø§Ø¯ÙŠ', 'ÙˆÙŠØ´Ø¬Ø¹ÙˆÙ†Ù‡Ù…', 'Ø·ÙˆÙ„', 'Ø§Ù„ÙˆÙ‚Øª', '.', '.', '.', '.', '.', 'Ø§Ù„Ù„Ø§Ø¹Ø¨', 'Ø§Ø°Ø§', 'Ø­ØµÙ„', 'Ø¹Ø±Ø¶', 'Ø¨ÙŠØ±ÙˆØ­', 'Ù„ÙƒÙ†', 'Ø§Ù„Ù…Ø´Ø¬Ø¹', 'Ø¨Ø§Ù‚ÙŠ', 'Ø¨ÙŠØ¨', 'Ù„ÙƒÙ…', 'Ø¬Ù…Ø§Ù‡ÙŠØ±', 'ÙˆÙ„Ø§Ø¹Ø¨ÙŠÙ†', 'ÙŠÙ„Ø¹Ø¨ÙˆÙ†', 'ÙÙŠ', 'Ø§Ù„Ù…Ø±Ø§Ø­Ù„', '.', '.', '.', '.', '.', 'ÙˆÙ…Ø³ØªÙƒØ«Ø±', 'Ø¹Ù„ÙŠ', 'Ù‡Ø°Ø§', 'Ø§Ù„Ù…Ø´Ø¬Ø¹', 'ÙˆÙ„Ø¯', 'Ø§Ù„Ù†Ø§Ø¯ÙŠ', 'Ø§Ù„Ù„ÙŠ', 'Ù…Ø§', 'Ø§Ø¹Ø±ÙÙ‡', 'ÙˆÙ„Ø§', 'Ø§Ø¹Ø±Ù', 'Ù†Ø§Ø¯ÙŠÙ‡', 'Ø§Ù†Ù‡Ù…', 'ÙŠÙˆØ¯ÙˆÙ†Ù‡'], ['Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ', 'Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ', 'Ø§Ù„Ù„Ù‡', 'ÙŠØ³Ù„Ù…Ùƒ', 'ÙŠØ§Ø¨Ùˆ', 'Ø¹Ø²ÙˆØ²', 'ÙˆØ§Ø¨Ø´Ø±Ùƒ', 'Ø·ÙŠØ¨', 'Ù„ÙƒÙ†', 'Ø°Ø¨Ø­Ù†Ø§', 'Ø§Ù„Ø¨Ø±Ø¯', 'ÙÙŠ', 'ÙØ±Ø§Ù†ÙƒÙÙˆØ±Øª', '.', '.']]\n"
     ]
    }
   ],
   "source": [
    "x_train_text_tokenized = tokenize_using_nltk_TreebankWordTokenizer(x_train_text)\n",
    "\n",
    "print(\"Before Tokenization : \\n\", x_train_text[:3])\n",
    "print(\"=\"*50)\n",
    "print(\"After Tokenization : \\n\", x_train_text_tokenized[:3])\n",
    "print(\"=\"*50)\n",
    "\n",
    "x_val_text_tokenized = tokenize_using_nltk_TreebankWordTokenizer(x_val_text)\n",
    "\n",
    "print(\"Before Tokenization : \\n\", x_val_text[:3])\n",
    "print(\"=\"*50)\n",
    "print(\"After Tokenization : \\n\", x_val_text_tokenized[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc85e489",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_vec_model = load_word2vec_model(\"models/word2vec/rezk_unigram_CBOW_model/train_word2vec_cbow__window_3_min_count_300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3316ece3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4900, 19200)\n",
      "==================================================\n",
      "[-0.1262   0.2761   0.2466  -0.3464  -0.5044   0.216    0.2651   0.05423\n",
      " -0.3276  -0.2793   0.328    0.1699  -0.05267  0.1941   0.292    0.1654\n",
      " -0.01619 -0.428    0.411    0.0927   0.271    0.6206  -0.04764  0.04465\n",
      "  0.0863   0.06042  0.08374 -0.0927   0.05176 -0.1616  -0.4875   0.4932\n",
      "  0.1333   0.4666   0.0387  -0.19     0.05563 -0.1526   0.549    0.2966\n",
      " -0.0969  -0.345   -0.2896  -0.0667   0.12146  0.2126   0.1146  -0.4404\n",
      " -0.1198   0.2651 ]\n",
      "(100, 19200)\n",
      "==================================================\n",
      "[-0.4592   0.2432   0.1448  -0.4316   0.6978  -0.1765  -0.1914   0.1428\n",
      "  0.5747   0.5137  -0.221    0.11597  0.662    0.0326   0.1252  -0.2151\n",
      " -0.1257  -0.07007 -0.6455  -0.2339   0.306   -0.3018   0.4214  -0.404\n",
      " -0.0551   0.6265  -0.04926  0.2296  -0.3257   0.4802  -0.0753   1.139\n",
      " -0.1752   0.347    0.3054  -0.1255  -0.0935  -0.2761  -0.00686  0.388\n",
      "  0.7505  -0.04257  0.333   -0.1248   0.1353   0.2834  -0.04108 -0.5044\n",
      "  0.603   -0.2319 ]\n"
     ]
    }
   ],
   "source": [
    "number_of_features = 300\n",
    "max_len_str = 64\n",
    "word2vec_path = \"rezk/\"\n",
    "model_path_to_save = \"models/ml_models/\"\n",
    "estimators = voting_models()\n",
    "\n",
    "X_train_embed_matrix = text_to_matrix_using_word2vec(word_to_vec_model, x_train_text_tokenized, max_len_str)\n",
    "X_val_embed_matrix = text_to_matrix_using_word2vec(word_to_vec_model, x_val_text_tokenized, max_len_str)\n",
    "\n",
    "X_train_embed_matrix = X_train_embed_matrix.reshape(X_train_embed_matrix.shape[0], max_len_str, number_of_features)\n",
    "X_val_embed_matrix = X_val_embed_matrix.reshape(X_val_embed_matrix.shape[0], max_len_str, number_of_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1eaa153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 64, 50)            70200     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64, 50)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 18)                57618     \n",
      "=================================================================\n",
      "Total params: 127,818\n",
      "Trainable params: 127,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      " 43/154 [=======>......................] - ETA: 3s - loss: 2.8721 - accuracy: 0.0850"
     ]
    }
   ],
   "source": [
    "num_nuros = 50\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(num_nuros, return_sequences=True, input_shape=(max_len_str, number_of_features)))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(18, activation=\"softmax\"))\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "         optimizer=\"sgd\",\n",
    "         metrics=\"accuracy\")\n",
    "model.summary()\n",
    "history = model.fit(X_train_embed_matrix, y_train, batch_size=32, epochs=10, validation_data=(X_val_embed_matrix, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed4fa5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20aaa6d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d4a52c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddefd9d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
