{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39058f6b",
   "metadata": {},
   "source": [
    "# Used Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100296d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from typing import Optional\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "from fastapi.encoders import jsonable_encoder\n",
    "from fastapi import FastAPI\n",
    "from enum import Enum\n",
    "import os\n",
    "import io\n",
    "import pickle\n",
    "import uvicorn\n",
    "import nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c1c8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_tweet(tweets, model):\n",
    "    '''\n",
    "    The function used to classify tweets, but during to the model design it take a list of tweets,\n",
    "    and return numpy array, so we have do some manipulation before return the data.\n",
    "    \n",
    "    Argument:\n",
    "        tweets: dictionary of tweet text and default value = 0\n",
    "        model: Enum of two string which the model you need to choose\n",
    "    Return:\n",
    "        classifed_tweet: dictionary of tweet text and default value = negative\n",
    "    '''\n",
    "    \n",
    "    # get the tweet text as string then convert to list\n",
    "    tweet = [tweets['tweet_text']]\n",
    "    \n",
    "    # Get the text features using Tf-Idf vectorization model\n",
    "    tweets_features = tf_idf_model.transform(tweet)\n",
    "    \n",
    "    # convert to sparse matrix instead of compressed space type\n",
    "    tweets_features_array = tweets_features.toarray()\n",
    "    \n",
    "    \n",
    "    # Check which model you need to predicit \n",
    "    if model == \"Logistic_Model\":\n",
    "        print(\"Prediction using Logistic Model\")\n",
    "        print(\"=\"*50)\n",
    "        predict = log_reg_model.predict(tweets_features_array)\n",
    "    else:\n",
    "        print(\"Prediction using RandomForest Model\")\n",
    "        print(\"=\"*50)\n",
    "        predict = randforest_model.predict(tweets_features_array)\n",
    "        \n",
    "    \n",
    "    pred_result = 'Positive' if predict[0] == 1 else 'Negative'\n",
    "    \n",
    "    # Return dictionary\n",
    "    classifed_tweet = {\n",
    "        'tweet_text': tweet,\n",
    "        'predict_class': pred_result\n",
    "#         'predict_class': predict\n",
    "    }\n",
    "    return classifed_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a126513",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_tweet(tweet_indx_with_100, model_type):\n",
    "    test_tweet = list(covid_tweets_data['cleaned_tweet_text'])[tweet_indx_with_100]\n",
    "    print(test_tweet)\n",
    "    print(\"=============== True Value for this tweet ===================\")\n",
    "    print(\"=============== \" + str(covid_tweets_data['class'][tweet_indx_with_100]) + \" ===================\")\n",
    "    \n",
    "    print(\"=\"*50)\n",
    "    tweet_dict = {\n",
    "        'tweet_text': test_tweet,\n",
    "        'predict_class': '0'\n",
    "    }\n",
    "    \n",
    "    return classify_tweet(tweet_dict, model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44536980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign an instance of the FastAPI class to the variable \"app\".\n",
    "# You will interact with your api using this instance.\n",
    "app = FastAPI(title='Deploying a ML & DL Model with FastAPI')\n",
    "\n",
    "# List available models using Enum\n",
    "class Model(str, Enum):\n",
    "    ML_Model = \"Machine Learning Model\"\n",
    "    DL_Model = \"Deep Learning Model\"\n",
    "\n",
    "\n",
    "class Tweet_Text(BaseModel):\n",
    "    tweet_text: str = \"\"\"ممثل منظمه الصحه العالميه في مصر يحدث في مصر اثق تماما في الاجراءات تتخذها مصر لمواجهه وباء محتمل MBCMASR \"\"\"\n",
    "    predict_class: str = 'IQ'\n",
    "        \n",
    "\n",
    "@app.get(\"/\")\n",
    "def home():\n",
    "    # Once you go to this link you will see the get and post method below to trying out\n",
    "    return \"Congratulations! Your API is working as expected. Now head over to http://localhost:5000/docs.\"\n",
    "\n",
    "\n",
    "# This endpoint handles all the logic necessary for the object detection to work.\n",
    "# It requires the desired model and the dictionary of tweet and default class as we give default values to us\n",
    "# In the api you can try other tweet from some_tweets below\n",
    "@app.post(\"/predict\") \n",
    "def prediction(model: Model, tweet: Tweet_Text):\n",
    "    \n",
    "    # Encode the retrived request data \n",
    "    tweet = jsonable_encoder(tweet)\n",
    "    \n",
    "    # Run our model\n",
    "    classifed_tweet = classify_tweet(tweet, model=model)\n",
    "    \n",
    "    return classifed_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095039d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allows the server to be run in this interactive environment\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Host depends on the setup you selected (docker or virtual env)\n",
    "host = \"0.0.0.0\" if os.getenv(\"DOCKER-SETUP\") else \"127.0.0.1\"\n",
    "\n",
    "# uvicorn is fast Asynchronous Server Gateway Interface (ASGI) uvicorn handles the serving\n",
    "# Spin up the server!    \n",
    "uvicorn.run(app, host=host, port=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f58cd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
