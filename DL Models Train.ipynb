{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2595a258",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, LSTM, Embedding\n",
    "from configs import *\n",
    "from fetch_data import *\n",
    "from features_extraction import *\n",
    "from data_shuffling_split import *\n",
    "from data_preprocess import *\n",
    "from ml_modeling import *\n",
    "from keras_models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8deed7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances in the file are:  449033\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dialect</th>\n",
       "      <th>dialect_l_encoded</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1056552188082716800</td>\n",
       "      <td>LY</td>\n",
       "      <td>8</td>\n",
       "      <td>ØªÙˆØ§ Ø¯ÙˆØ´Ù‡ Ø§Ù„ÙƒÙ„Ø§Ø³ÙŠÙƒÙˆ Ø´Ù† Ø¨ÙŠØªÙ…Ù‡Ø§ ÙˆØ´Ù† Ø¨ÙŠØ³ÙƒØªÙ‡Ù… ÙˆØ´Ù† Ø¨...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>891734969202114560</td>\n",
       "      <td>SY</td>\n",
       "      <td>15</td>\n",
       "      <td>Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ ÙÙŠ Ø§Ø­Ù„ÙŠ Ù…Ù† Ø§Ù„Ø´Ø­Ø§Ø·Ù‡ ğŸ˜‚</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1110565179257954432</td>\n",
       "      <td>SD</td>\n",
       "      <td>14</td>\n",
       "      <td>Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ Ù…ÙˆÙ‡Ø¨Ù‡ ÙˆØ§Ù„Ù„Ù‡ ğŸ˜‚ Ø§ÙˆØ¹ ØªØ­Ø§ÙˆÙ„ ØªØ·ÙˆØ±Ù‡Ø§ ØªÙ‚ÙˆÙ… Ù…...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1172817955270340608</td>\n",
       "      <td>LB</td>\n",
       "      <td>7</td>\n",
       "      <td>Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ ğŸ˜‚ Ø§Ù†Ø§ ØµØ±Ù„ÙŠ Ø¹Ø´Ø± Ø³Ù†ÙŠÙ† Ù…Ø´ Ù…Ø¬Ø¯Ø¯Ù‡...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>293253217821790208</td>\n",
       "      <td>QA</td>\n",
       "      <td>12</td>\n",
       "      <td>Ø§Ø­Ù„ÙŠ Ø´Ø¹ÙˆØ± ØªÙƒÙˆÙ† Ø¨Ø§Ø¬Ø§Ø²Ù‡ ÙˆØªÙ‚ÙˆÙ… Ù…Ù† Ø§Ù„ØµØ¨Ø­ ÙˆØªÙ…Ø± Ø¹ Ø§Ù„...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id dialect  dialect_l_encoded  \\\n",
       "0  1056552188082716800      LY                  8   \n",
       "1   891734969202114560      SY                 15   \n",
       "2  1110565179257954432      SD                 14   \n",
       "3  1172817955270340608      LB                  7   \n",
       "4   293253217821790208      QA                 12   \n",
       "\n",
       "                                                text  \n",
       "0  ØªÙˆØ§ Ø¯ÙˆØ´Ù‡ Ø§Ù„ÙƒÙ„Ø§Ø³ÙŠÙƒÙˆ Ø´Ù† Ø¨ÙŠØªÙ…Ù‡Ø§ ÙˆØ´Ù† Ø¨ÙŠØ³ÙƒØªÙ‡Ù… ÙˆØ´Ù† Ø¨...  \n",
       "1                     Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ ÙÙŠ Ø§Ø­Ù„ÙŠ Ù…Ù† Ø§Ù„Ø´Ø­Ø§Ø·Ù‡ ğŸ˜‚   \n",
       "2  Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ Ù…ÙˆÙ‡Ø¨Ù‡ ÙˆØ§Ù„Ù„Ù‡ ğŸ˜‚ Ø§ÙˆØ¹ ØªØ­Ø§ÙˆÙ„ ØªØ·ÙˆØ±Ù‡Ø§ ØªÙ‚ÙˆÙ… Ù…...  \n",
       "3  Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ ğŸ˜‚ Ø§Ù†Ø§ ØµØ±Ù„ÙŠ Ø¹Ø´Ø± Ø³Ù†ÙŠÙ† Ù…Ø´ Ù…Ø¬Ø¯Ø¯Ù‡...  \n",
       "4  Ø§Ø­Ù„ÙŠ Ø´Ø¹ÙˆØ± ØªÙƒÙˆÙ† Ø¨Ø§Ø¬Ø§Ø²Ù‡ ÙˆØªÙ‚ÙˆÙ… Ù…Ù† Ø§Ù„ØµØ¨Ø­ ÙˆØªÙ…Ø± Ø¹ Ø§Ù„...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strat_train_set = read_csv(\"train/strat_train_set.csv\")\n",
    "strat_train_set = strat_train_set.iloc[:5000]\n",
    "strat_train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df9dd098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of instances in the training data after StratifiedShuffleSplit are:  4900\n",
      "The number of instances in the testing data after StratifiedShuffleSplit are:   100\n",
      "The number of trainin instances:  4900\n",
      "The number of validation instances:  100\n",
      "The number of trainin labels :  4900\n",
      "The number of validation labels :  100\n"
     ]
    }
   ],
   "source": [
    "x_train_text, x_val_text, y_train, y_val = prepare_data(strat_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0507dbfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Tokenization : \n",
      " ['Ø§Ù„Ø¬Ùˆ Ø¨Ø§Ù„Ø§Ø±Ø¯Ù† Ø­Ø§Ù„ÙŠØ§ Ù‡Ùˆ Ø§Ù„Ø¬Ùˆ Ø§Ù„Ù„ÙŠ Ø§Ù†Ø§ Ù…Ø´ØªØ§Ù‚ÙŠØªÙ„Ù‡ Ùˆ Ù†ÙØ³ÙŠ Ø§Ù†Ø²Ù„ Ø¹Ù„ÙŠÙ‡ . . . Ø¨ÙƒØ±Ø§ Ø¨Ø³ Ø§ÙˆØµÙ„ Ø§Ù„Ø§Ø±Ø¯Ù† Ø¯Ø±Ø¬Ø§Øª Ø§Ù„Ø­Ø±Ø§Ø±Ù‡ Ø­ØªØ±ØªÙØ¹ Ø§Ù†Ø§ Ø¹Ø§Ø±ÙÙ‡ Ø­Ø¸ÙŠ Ø§Ù„Ù…Ù†Ø­ÙˆØ³ ğŸ˜­ ', 'Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ ØªØ¹Ø±Ù Ø§Ù„ÙŠ Ù…Ù† ØªØ®Ù„Øµ Ø§Ù„Ù‡ÙˆØ´Ù‡ ÙŠØ¬ÙŠÙƒ ÙŠØµØ§Ø±Ø® ÙˆÙŠÙ†Ù‡ ÙˆÙŠÙ†Ù‡ . . . . . Ø°Ø¨Ø­ÙˆÙ†Ø§', 'Ù…Ù„Ø§Ø° Ø§Ù„Ø±ÙˆØ­ Ø¶ÙˆÙŠ Ø¹ÙŠÙˆÙ†ÙŠ ÙˆÙÙ‡Ù… Ø·Ø¨Ø¹ÙŠ Ù…Ø¹ Ø¬Ù†ÙˆÙ†ÙŠ ØªØ­Ù…Ù„Ù†ÙŠ ÙˆÙ…Ù‚ØªÙ†Ø¹ ÙÙŠÙ†ÙŠ ÙˆÙ„Ø§ÙˆØ¯ÙŠ Ø¨Ø§Ø­Ø¯ ØºÙŠØ±Ù‡ Ø®Ø°Ø§Ù†ÙŠ Ù‡ÙˆØ§Ù‡ ÙˆÙƒÙ…Ù„Ù†ÙŠ ÙˆÙ…Ø«Ù„ÙŠ ØµØ§Ø± ÙŠØ¹Ø´Ù‚Ù†ÙŠ Ù…Ù„Ø§Ù†ÙŠ ØºØ±Ø§Ù… ÙˆÙØ§Ù‡Ù…Ù†ÙŠ ÙˆÙ„Ù‡ Ø¨Ø¹ÙŠÙˆÙ†ÙŠ ØºÙ„Ø§ ÙˆØ¯ÙŠØ±Ù‡ #Ø³Ù…Ø±_Ø§Ù„Ø¨Ø­Ø±ÙŠÙ†ÙŠÙ‡ ğŸ‡§ğŸ‡­ ']\n",
      "==================================================\n",
      "After Tokenization : \n",
      " [['Ø§Ù„Ø¬Ùˆ', 'Ø¨Ø§Ù„Ø§Ø±Ø¯Ù†', 'Ø­Ø§Ù„ÙŠØ§', 'Ù‡Ùˆ', 'Ø§Ù„Ø¬Ùˆ', 'Ø§Ù„Ù„ÙŠ', 'Ø§Ù†Ø§', 'Ù…Ø´ØªØ§Ù‚ÙŠØªÙ„Ù‡', 'Ùˆ', 'Ù†ÙØ³ÙŠ', 'Ø§Ù†Ø²Ù„', 'Ø¹Ù„ÙŠÙ‡', '.', '.', '.', 'Ø¨ÙƒØ±Ø§', 'Ø¨Ø³', 'Ø§ÙˆØµÙ„', 'Ø§Ù„Ø§Ø±Ø¯Ù†', 'Ø¯Ø±Ø¬Ø§Øª', 'Ø§Ù„Ø­Ø±Ø§Ø±Ù‡', 'Ø­ØªØ±ØªÙØ¹', 'Ø§Ù†Ø§', 'Ø¹Ø§Ø±ÙÙ‡', 'Ø­Ø¸ÙŠ', 'Ø§Ù„Ù…Ù†Ø­ÙˆØ³', 'ğŸ˜­'], ['Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ', 'ØªØ¹Ø±Ù', 'Ø§Ù„ÙŠ', 'Ù…Ù†', 'ØªØ®Ù„Øµ', 'Ø§Ù„Ù‡ÙˆØ´Ù‡', 'ÙŠØ¬ÙŠÙƒ', 'ÙŠØµØ§Ø±Ø®', 'ÙˆÙŠÙ†Ù‡', 'ÙˆÙŠÙ†Ù‡', '.', '.', '.', '.', '.', 'Ø°Ø¨Ø­ÙˆÙ†Ø§'], ['Ù…Ù„Ø§Ø°', 'Ø§Ù„Ø±ÙˆØ­', 'Ø¶ÙˆÙŠ', 'Ø¹ÙŠÙˆÙ†ÙŠ', 'ÙˆÙÙ‡Ù…', 'Ø·Ø¨Ø¹ÙŠ', 'Ù…Ø¹', 'Ø¬Ù†ÙˆÙ†ÙŠ', 'ØªØ­Ù…Ù„Ù†ÙŠ', 'ÙˆÙ…Ù‚ØªÙ†Ø¹', 'ÙÙŠÙ†ÙŠ', 'ÙˆÙ„Ø§ÙˆØ¯ÙŠ', 'Ø¨Ø§Ø­Ø¯', 'ØºÙŠØ±Ù‡', 'Ø®Ø°Ø§Ù†ÙŠ', 'Ù‡ÙˆØ§Ù‡', 'ÙˆÙƒÙ…Ù„Ù†ÙŠ', 'ÙˆÙ…Ø«Ù„ÙŠ', 'ØµØ§Ø±', 'ÙŠØ¹Ø´Ù‚Ù†ÙŠ', 'Ù…Ù„Ø§Ù†ÙŠ', 'ØºØ±Ø§Ù…', 'ÙˆÙØ§Ù‡Ù…Ù†ÙŠ', 'ÙˆÙ„Ù‡', 'Ø¨Ø¹ÙŠÙˆÙ†ÙŠ', 'ØºÙ„Ø§', 'ÙˆØ¯ÙŠØ±Ù‡', '#', 'Ø³Ù…Ø±_Ø§Ù„Ø¨Ø­Ø±ÙŠÙ†ÙŠÙ‡', 'ğŸ‡§ğŸ‡­']]\n",
      "==================================================\n",
      "Before Tokenization : \n",
      " ['Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ Ø±Ø¨ÙŠ ÙŠØ±Ø¯ ÙƒÙ„ ØºØ§Ø¦Ø¨ ÙŠØ§ Ø§ÙŠÙ…ÙŠ ÙˆØ§Ø¹Ø°Ø±ÙŠÙ†Ø§ Ù…Ù† Ù‚Ù‡Ø±Ù†Ø§', 'Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ Ù…Ø§ ÙÙŠÙƒ Ø¹Ù†Ø§ Ø§Ù„Ø¯Ø³ØªÙˆØ± Ù…Ø§ Ø¨ÙŠØ³Ù…Ø­ Ù„Ø§Ù†Ùˆ Ù‚Ø§Ù†ÙˆÙ† Ø°Ø§ØªÙŠ Ø´Ø¨ÙŠÙ‡ Ø¨Ø§Ù„ØªÙ‚Ø³ÙŠÙ… Ø§ØµÙ„Ø§ Ø¹Ù†Ø§ Ø§Ù„Ø·ÙˆØ§Ø¦Ù Ø´Ø¨ÙŠÙ‡Ù‡ Ø¨Ø§Ù„ÙØ¯Ø±Ø§Ù„ÙŠÙ‡ ÙƒÙ„ Ø·Ø§Ø¦ÙÙ‡ Ø¨ÙŠØ­ÙƒÙ…Ùˆ Ø­Ø§Ù„Ù†', 'Ø§Ø³Ø§Ù„Ùˆ #Ø§Ù„Ø¨Ø±Ø´Ù„ÙˆÙ†ÙŠÙ‡ Ø¬Ù…Ù„Ù‡Ù… Ù…Ø§ØªØ®Ù„Øµ ğŸ˜‚ #Ø¬Ù…Ù„Ù‡_ÙƒØ±ÙˆÙŠÙ‡_ØªØºØ«Ùƒ']\n",
      "==================================================\n",
      "After Tokenization : \n",
      " [['Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ', 'Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ', 'Ø±Ø¨ÙŠ', 'ÙŠØ±Ø¯', 'ÙƒÙ„', 'ØºØ§Ø¦Ø¨', 'ÙŠØ§', 'Ø§ÙŠÙ…ÙŠ', 'ÙˆØ§Ø¹Ø°Ø±ÙŠÙ†Ø§', 'Ù…Ù†', 'Ù‚Ù‡Ø±Ù†Ø§'], ['Ø­Ø³Ø§Ø¨Ø´Ø®ØµÙŠ', 'Ù…Ø§', 'ÙÙŠÙƒ', 'Ø¹Ù†Ø§', 'Ø§Ù„Ø¯Ø³ØªÙˆØ±', 'Ù…Ø§', 'Ø¨ÙŠØ³Ù…Ø­', 'Ù„Ø§Ù†Ùˆ', 'Ù‚Ø§Ù†ÙˆÙ†', 'Ø°Ø§ØªÙŠ', 'Ø´Ø¨ÙŠÙ‡', 'Ø¨Ø§Ù„ØªÙ‚Ø³ÙŠÙ…', 'Ø§ØµÙ„Ø§', 'Ø¹Ù†Ø§', 'Ø§Ù„Ø·ÙˆØ§Ø¦Ù', 'Ø´Ø¨ÙŠÙ‡Ù‡', 'Ø¨Ø§Ù„ÙØ¯Ø±Ø§Ù„ÙŠÙ‡', 'ÙƒÙ„', 'Ø·Ø§Ø¦ÙÙ‡', 'Ø¨ÙŠØ­ÙƒÙ…Ùˆ', 'Ø­Ø§Ù„Ù†'], ['Ø§Ø³Ø§Ù„Ùˆ', '#', 'Ø§Ù„Ø¨Ø±Ø´Ù„ÙˆÙ†ÙŠÙ‡', 'Ø¬Ù…Ù„Ù‡Ù…', 'Ù…Ø§ØªØ®Ù„Øµ', 'ğŸ˜‚', '#', 'Ø¬Ù…Ù„Ù‡_ÙƒØ±ÙˆÙŠÙ‡_ØªØºØ«Ùƒ']]\n"
     ]
    }
   ],
   "source": [
    "x_train_text_tokenized = tokenize_using_nltk_TreebankWordTokenizer(x_train_text)\n",
    "\n",
    "print(\"Before Tokenization : \\n\", x_train_text[:3])\n",
    "print(\"=\"*50)\n",
    "print(\"After Tokenization : \\n\", x_train_text_tokenized[:3])\n",
    "print(\"=\"*50)\n",
    "\n",
    "x_val_text_tokenized = tokenize_using_nltk_TreebankWordTokenizer(x_val_text)\n",
    "\n",
    "print(\"Before Tokenization : \\n\", x_val_text[:3])\n",
    "print(\"=\"*50)\n",
    "print(\"After Tokenization : \\n\", x_val_text_tokenized[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df71f55",
   "metadata": {},
   "source": [
    "# LSTM Model with Bakr Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc85e489",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_vec_model = load_word2vec_model(\"models/word2vec/bakrianoo_unigram_cbow_model/full_uni_cbow_100_twitter.mdl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3316ece3",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len_str = 64\n",
    "hid_num_neurons = 50\n",
    "learning_rate = .1\n",
    "epochs = 30\n",
    "\n",
    "performance_lr = keras.callbacks.ReduceLROnPlateau(factor=.5, patience=5)\n",
    "SGD_optimizer     =keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "Adam_optimizer = keras.optimizers.Adam(beta_1=0.9, beta_2=0.999)\n",
    "RMSprop_optimizer = keras.optimizers.RMSprop(learning_rate=learning_rate, rho=.9)\n",
    "\n",
    "\n",
    "callbacks_ = keras_callbacks(word2vec_type=\"bakr_word2vec\", model_type=\"lstm_no_batch\", learning_rate=learning_rate)\n",
    "callbacks_.append(performance_lr)\n",
    "\n",
    "number_of_features = 100\n",
    "word2vec_path = \"bakr/\"\n",
    "\n",
    "X_train_embed_matrix = text_to_matrix_using_word2vec(word_to_vec_model, x_train_text_tokenized, max_len_str)\n",
    "X_val_embed_matrix = text_to_matrix_using_word2vec(word_to_vec_model, x_val_text_tokenized, max_len_str)\n",
    "\n",
    "# Reshape because of deep learning model\n",
    "X_train_embed_matrix = X_train_embed_matrix.reshape(X_train_embed_matrix.shape[0], max_len_str, number_of_features)\n",
    "X_val_embed_matrix = X_val_embed_matrix.reshape(X_val_embed_matrix.shape[0], max_len_str, number_of_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e2eb48",
   "metadata": {},
   "source": [
    "# With  SGD and No Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4faff520",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lstm_no_batch_seqential_model_create(hid_num_neurons, max_len_str, number_of_features, dropout=.2)\n",
    "model = seqential_model_compile(model, SGD_optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1daff47",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_embed_matrix, y_train, batch_size=32, epochs=epochs, validation_data=(X_val_embed_matrix, y_val),\n",
    "                   callbacks=callbacks_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604d05d4",
   "metadata": {},
   "source": [
    "# With  Adam and No Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dacb5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lstm_no_batch_seqential_model_create(hid_num_neurons, max_len_str, number_of_features, dropout=.2)\n",
    "model = seqential_model_compile(model, Adam_optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319b4d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_embed_matrix, y_train, batch_size=32, epochs=epochs, validation_data=(X_val_embed_matrix, y_val),\n",
    "                   callbacks=callbacks_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59db30a1",
   "metadata": {},
   "source": [
    "# With  RMSprob and No Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf79d92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lstm_no_batch_seqential_model_create(hid_num_neurons, max_len_str, number_of_features, dropout=.2)\n",
    "model = seqential_model_compile(model, RMSprop_optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c01491",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_embed_matrix, y_train, batch_size=32, epochs=epochs, validation_data=(X_val_embed_matrix, y_val),\n",
    "                   callbacks=callbacks_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6108087",
   "metadata": {},
   "source": [
    "# With  SGD and Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345f2548",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_ = keras_callbacks(word2vec_type=\"bakr_word2vec\", model_type=\"lstm_with_batch\", learning_rate=learning_rate)\n",
    "callbacks_.append(performance_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9885180",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lstm_with_batch_model_create(hid_num_neurons, max_len_str, number_of_features, dropout=.2)\n",
    "model = seqential_model_compile(model, SGD_optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b044bf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_embed_matrix, y_train, batch_size=32, epochs=epochs, validation_data=(X_val_embed_matrix, y_val),\n",
    "                   callbacks=callbacks_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710f10e3",
   "metadata": {},
   "source": [
    "# With  Adam and No Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c9b1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lstm_with_batch_model_create(hid_num_neurons, max_len_str, number_of_features, dropout=.2)\n",
    "model = seqential_model_compile(model, Adam_optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f32e1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_embed_matrix, y_train, batch_size=32, epochs=epochs, validation_data=(X_val_embed_matrix, y_val),\n",
    "                   callbacks=callbacks_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ec6317",
   "metadata": {},
   "source": [
    "# With  RMSprob and No Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e35a6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lstm_with_batch_model_create(hid_num_neurons, max_len_str, number_of_features, dropout=.2)\n",
    "model = seqential_model_compile(model, RMSprop_optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae74e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_embed_matrix, y_train, batch_size=32, epochs=epochs, validation_data=(X_val_embed_matrix, y_val),\n",
    "                   callbacks=callbacks_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349c9cb3",
   "metadata": {},
   "source": [
    "# LSTM Model with Rezk Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfaa4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_vec_model = load_word2vec_model(\"models/word2vec/rezk_unigram_CBOW_model/train_word2vec_cbow__window_3_min_count_300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585603b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_features = 300\n",
    "\n",
    "callbacks_ = keras_callbacks(word2vec_type=\"rezk_word2vec\", model_type=\"lstm_no_batch\", learning_rate=learning_rate)\n",
    "callbacks_.append(performance_lr)\n",
    "\n",
    "word2vec_path = \"rezk/\"\n",
    "\n",
    "X_train_embed_matrix = text_to_matrix_using_word2vec(word_to_vec_model, x_train_text_tokenized, max_len_str)\n",
    "X_val_embed_matrix = text_to_matrix_using_word2vec(word_to_vec_model, x_val_text_tokenized, max_len_str)\n",
    "\n",
    "# Reshape because of deep learning model\n",
    "X_train_embed_matrix = X_train_embed_matrix.reshape(X_train_embed_matrix.shape[0], max_len_str, number_of_features)\n",
    "X_val_embed_matrix = X_val_embed_matrix.reshape(X_val_embed_matrix.shape[0], max_len_str, number_of_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d2cb5d",
   "metadata": {},
   "source": [
    "# With  SGD and No Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c06bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lstm_no_batch_seqential_model_create(hid_num_neurons, max_len_str, number_of_features, dropout=.2)\n",
    "model = seqential_model_compile(model, SGD_optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc13c790",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_embed_matrix, y_train, batch_size=32, epochs=epochs, validation_data=(X_val_embed_matrix, y_val),\n",
    "                   callbacks=callbacks_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9039b01a",
   "metadata": {},
   "source": [
    "# With  Adam and No Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819acdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lstm_no_batch_seqential_model_create(hid_num_neurons, max_len_str, number_of_features, dropout=.2)\n",
    "model = seqential_model_compile(model, Adam_optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4900d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_embed_matrix, y_train, batch_size=32, epochs=epochs, validation_data=(X_val_embed_matrix, y_val),\n",
    "                   callbacks=callbacks_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e063ebd",
   "metadata": {},
   "source": [
    "# With  Rmsprob and No Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b670cb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lstm_no_batch_seqential_model_create(hid_num_neurons, max_len_str, number_of_features, dropout=.2)\n",
    "model = seqential_model_compile(model, RMSprop_optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f7b283",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_embed_matrix, y_train, batch_size=32, epochs=epochs, validation_data=(X_val_embed_matrix, y_val),\n",
    "                   callbacks=callbacks_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5cd987",
   "metadata": {},
   "source": [
    "# With  SGD and  Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4913a492",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_ = keras_callbacks(word2vec_type=\"rezk_word2vec\", model_type=\"lstm_with_batch\", learning_rate=learning_rate)\n",
    "callbacks_.append(performance_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77200e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lstm_with_batch_model_create(hid_num_neurons, max_len_str, number_of_features, dropout=.2)\n",
    "model = seqential_model_compile(model, SGD_optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8183108f",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_embed_matrix, y_train, batch_size=32, epochs=epochs, validation_data=(X_val_embed_matrix, y_val),\n",
    "                   callbacks=callbacks_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b114d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lstm_with_batch_model_create(hid_num_neurons, max_len_str, number_of_features, dropout=.2)\n",
    "model = seqential_model_compile(model, Adam_optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed077d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_embed_matrix, y_train, batch_size=32, epochs=epochs, validation_data=(X_val_embed_matrix, y_val),\n",
    "                   callbacks=callbacks_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23143f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lstm_with_batch_model_create(hid_num_neurons, max_len_str, number_of_features, dropout=.2)\n",
    "model = seqential_model_compile(model, RMSprop_optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588df895",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_embed_matrix, y_train, batch_size=32, epochs=epochs, validation_data=(X_val_embed_matrix, y_val),\n",
    "                   callbacks=callbacks_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
