{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2595a258",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, LSTM, Embedding\n",
    "from configs import *\n",
    "from fetch_data import *\n",
    "from features_extraction import *\n",
    "from data_shuffling_split import *\n",
    "from data_preprocess import *\n",
    "from ml_modeling import *\n",
    "from keras_models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8deed7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances in the file are:  449033\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dialect</th>\n",
       "      <th>dialect_l_encoded</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1056552188082716800</td>\n",
       "      <td>LY</td>\n",
       "      <td>8</td>\n",
       "      <td>ุชูุง ุฏูุดู ุงูููุงุณููู ุดู ุจูุชููุง ูุดู ุจูุณูุชูู ูุดู ุจ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>891734969202114560</td>\n",
       "      <td>SY</td>\n",
       "      <td>15</td>\n",
       "      <td>ุญุณุงุจุดุฎุตู ูู ุงุญูู ูู ุงูุดุญุงุทู ๐</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1110565179257954432</td>\n",
       "      <td>SD</td>\n",
       "      <td>14</td>\n",
       "      <td>ุญุณุงุจุดุฎุตู ูููุจู ูุงููู ๐ ุงูุน ุชุญุงูู ุชุทูุฑูุง ุชููู ู...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1172817955270340608</td>\n",
       "      <td>LB</td>\n",
       "      <td>7</td>\n",
       "      <td>ุญุณุงุจุดุฎุตู ุญุณุงุจุดุฎุตู ๐ ุงูุง ุตุฑูู ุนุดุฑ ุณููู ูุด ูุฌุฏุฏู...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>293253217821790208</td>\n",
       "      <td>QA</td>\n",
       "      <td>12</td>\n",
       "      <td>ุงุญูู ุดุนูุฑ ุชููู ุจุงุฌุงุฒู ูุชููู ูู ุงูุตุจุญ ูุชูุฑ ุน ุงู...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id dialect  dialect_l_encoded  \\\n",
       "0  1056552188082716800      LY                  8   \n",
       "1   891734969202114560      SY                 15   \n",
       "2  1110565179257954432      SD                 14   \n",
       "3  1172817955270340608      LB                  7   \n",
       "4   293253217821790208      QA                 12   \n",
       "\n",
       "                                                text  \n",
       "0  ุชูุง ุฏูุดู ุงูููุงุณููู ุดู ุจูุชููุง ูุดู ุจูุณูุชูู ูุดู ุจ...  \n",
       "1                     ุญุณุงุจุดุฎุตู ูู ุงุญูู ูู ุงูุดุญุงุทู ๐   \n",
       "2  ุญุณุงุจุดุฎุตู ูููุจู ูุงููู ๐ ุงูุน ุชุญุงูู ุชุทูุฑูุง ุชููู ู...  \n",
       "3  ุญุณุงุจุดุฎุตู ุญุณุงุจุดุฎุตู ๐ ุงูุง ุตุฑูู ุนุดุฑ ุณููู ูุด ูุฌุฏุฏู...  \n",
       "4  ุงุญูู ุดุนูุฑ ุชููู ุจุงุฌุงุฒู ูุชููู ูู ุงูุตุจุญ ูุชูุฑ ุน ุงู...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strat_train_set = read_csv(\"train/strat_train_set.csv\")\n",
    "strat_train_set = strat_train_set.iloc[:5000]\n",
    "strat_train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df9dd098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of instances in the training data after StratifiedShuffleSplit are:  4900\n",
      "The number of instances in the testing data after StratifiedShuffleSplit are:   100\n",
      "The number of trainin instances:  4900\n",
      "The number of validation instances:  100\n",
      "The number of trainin labels :  4900\n",
      "The number of validation labels :  100\n"
     ]
    }
   ],
   "source": [
    "x_train_text, x_val_text, y_train, y_val = prepare_data(strat_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0507dbfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Tokenization : \n",
      " ['ุงูุฌู ุจุงูุงุฑุฏู ุญุงููุง ูู ุงูุฌู ุงููู ุงูุง ูุดุชุงููุชูู ู ููุณู ุงูุฒู ุนููู . . . ุจูุฑุง ุจุณ ุงูุตู ุงูุงุฑุฏู ุฏุฑุฌุงุช ุงูุญุฑุงุฑู ุญุชุฑุชูุน ุงูุง ุนุงุฑูู ุญุธู ุงูููุญูุณ ๐ญ ', 'ุญุณุงุจุดุฎุตู ุชุนุฑู ุงูู ูู ุชุฎูุต ุงูููุดู ูุฌูู ูุตุงุฑุฎ ูููู ูููู . . . . . ุฐุจุญููุง', 'ููุงุฐ ุงูุฑูุญ ุถูู ุนูููู ูููู ุทุจุนู ูุน ุฌูููู ุชุญูููู ูููุชูุน ูููู ููุงูุฏู ุจุงุญุฏ ุบูุฑู ุฎุฐุงูู ููุงู ูููููู ููุซูู ุตุงุฑ ูุนุดููู ููุงูู ุบุฑุงู ููุงูููู ููู ุจุนูููู ุบูุง ูุฏูุฑู #ุณูุฑ_ุงูุจุญุฑูููู ๐ง๐ญ ']\n",
      "==================================================\n",
      "After Tokenization : \n",
      " [['ุงูุฌู', 'ุจุงูุงุฑุฏู', 'ุญุงููุง', 'ูู', 'ุงูุฌู', 'ุงููู', 'ุงูุง', 'ูุดุชุงููุชูู', 'ู', 'ููุณู', 'ุงูุฒู', 'ุนููู', '.', '.', '.', 'ุจูุฑุง', 'ุจุณ', 'ุงูุตู', 'ุงูุงุฑุฏู', 'ุฏุฑุฌุงุช', 'ุงูุญุฑุงุฑู', 'ุญุชุฑุชูุน', 'ุงูุง', 'ุนุงุฑูู', 'ุญุธู', 'ุงูููุญูุณ', '๐ญ'], ['ุญุณุงุจุดุฎุตู', 'ุชุนุฑู', 'ุงูู', 'ูู', 'ุชุฎูุต', 'ุงูููุดู', 'ูุฌูู', 'ูุตุงุฑุฎ', 'ูููู', 'ูููู', '.', '.', '.', '.', '.', 'ุฐุจุญููุง'], ['ููุงุฐ', 'ุงูุฑูุญ', 'ุถูู', 'ุนูููู', 'ูููู', 'ุทุจุนู', 'ูุน', 'ุฌูููู', 'ุชุญูููู', 'ูููุชูุน', 'ูููู', 'ููุงูุฏู', 'ุจุงุญุฏ', 'ุบูุฑู', 'ุฎุฐุงูู', 'ููุงู', 'ูููููู', 'ููุซูู', 'ุตุงุฑ', 'ูุนุดููู', 'ููุงูู', 'ุบุฑุงู', 'ููุงูููู', 'ููู', 'ุจุนูููู', 'ุบูุง', 'ูุฏูุฑู', '#', 'ุณูุฑ_ุงูุจุญุฑูููู', '๐ง๐ญ']]\n",
      "==================================================\n",
      "Before Tokenization : \n",
      " ['ุญุณุงุจุดุฎุตู ุญุณุงุจุดุฎุตู ุฑุจู ูุฑุฏ ูู ุบุงุฆุจ ูุง ุงููู ูุงุนุฐุฑููุง ูู ููุฑูุง', 'ุญุณุงุจุดุฎุตู ูุง ููู ุนูุง ุงูุฏุณุชูุฑ ูุง ุจูุณูุญ ูุงูู ูุงููู ุฐุงุชู ุดุจูู ุจุงูุชูุณูู ุงุตูุง ุนูุง ุงูุทูุงุฆู ุดุจููู ุจุงููุฏุฑุงููู ูู ุทุงุฆูู ุจูุญููู ุญุงูู', 'ุงุณุงูู #ุงูุจุฑุดููููู ุฌูููู ูุงุชุฎูุต ๐ #ุฌููู_ูุฑููู_ุชุบุซู']\n",
      "==================================================\n",
      "After Tokenization : \n",
      " [['ุญุณุงุจุดุฎุตู', 'ุญุณุงุจุดุฎุตู', 'ุฑุจู', 'ูุฑุฏ', 'ูู', 'ุบุงุฆุจ', 'ูุง', 'ุงููู', 'ูุงุนุฐุฑููุง', 'ูู', 'ููุฑูุง'], ['ุญุณุงุจุดุฎุตู', 'ูุง', 'ููู', 'ุนูุง', 'ุงูุฏุณุชูุฑ', 'ูุง', 'ุจูุณูุญ', 'ูุงูู', 'ูุงููู', 'ุฐุงุชู', 'ุดุจูู', 'ุจุงูุชูุณูู', 'ุงุตูุง', 'ุนูุง', 'ุงูุทูุงุฆู', 'ุดุจููู', 'ุจุงููุฏุฑุงููู', 'ูู', 'ุทุงุฆูู', 'ุจูุญููู', 'ุญุงูู'], ['ุงุณุงูู', '#', 'ุงูุจุฑุดููููู', 'ุฌูููู', 'ูุงุชุฎูุต', '๐', '#', 'ุฌููู_ูุฑููู_ุชุบุซู']]\n"
     ]
    }
   ],
   "source": [
    "x_train_text_tokenized = tokenize_using_nltk_TreebankWordTokenizer(x_train_text)\n",
    "\n",
    "print(\"Before Tokenization : \\n\", x_train_text[:3])\n",
    "print(\"=\"*50)\n",
    "print(\"After Tokenization : \\n\", x_train_text_tokenized[:3])\n",
    "print(\"=\"*50)\n",
    "\n",
    "x_val_text_tokenized = tokenize_using_nltk_TreebankWordTokenizer(x_val_text)\n",
    "\n",
    "print(\"Before Tokenization : \\n\", x_val_text[:3])\n",
    "print(\"=\"*50)\n",
    "print(\"After Tokenization : \\n\", x_val_text_tokenized[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df71f55",
   "metadata": {},
   "source": [
    "# LSTM Model with Bakr Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc85e489",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_vec_model = load_word2vec_model(\"models/word2vec/bakrianoo_unigram_cbow_model/full_uni_cbow_100_twitter.mdl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3316ece3",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len_str = 64\n",
    "hid_num_neurons = 50\n",
    "learning_rate = .1\n",
    "epochs = 30\n",
    "\n",
    "performance_lr = keras.callbacks.ReduceLROnPlateau(factor=.5, patience=5)\n",
    "SGD_optimizer     =keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "Adam_optimizer = keras.optimizers.Adam(beta_1=0.9, beta_2=0.999)\n",
    "RMSprop_optimizer = keras.optimizers.RMSprop(learning_rate=learning_rate, rho=.9)\n",
    "\n",
    "\n",
    "callbacks_ = keras_callbacks(word2vec_type=\"bakr_word2vec\", model_type=\"lstm_no_batch\", learning_rate=learning_rate)\n",
    "callbacks_.append(performance_lr)\n",
    "\n",
    "number_of_features = 100\n",
    "word2vec_path = \"bakr/\"\n",
    "\n",
    "X_train_embed_matrix = text_to_matrix_using_word2vec(word_to_vec_model, x_train_text_tokenized, max_len_str)\n",
    "X_val_embed_matrix = text_to_matrix_using_word2vec(word_to_vec_model, x_val_text_tokenized, max_len_str)\n",
    "\n",
    "# Reshape because of deep learning model\n",
    "X_train_embed_matrix = X_train_embed_matrix.reshape(X_train_embed_matrix.shape[0], max_len_str, number_of_features)\n",
    "X_val_embed_matrix = X_val_embed_matrix.reshape(X_val_embed_matrix.shape[0], max_len_str, number_of_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e2eb48",
   "metadata": {},
   "source": [
    "# With  SGD and No Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4faff520",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lstm_no_batch_seqential_model_create(hid_num_neurons, max_len_str, number_of_features, dropout=.2)\n",
    "model = seqential_model_compile(model, SGD_optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1daff47",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_embed_matrix, y_train, batch_size=32, epochs=epochs, validation_data=(X_val_embed_matrix, y_val),\n",
    "                   callbacks=callbacks_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604d05d4",
   "metadata": {},
   "source": [
    "# With  Adam and No Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dacb5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lstm_no_batch_seqential_model_create(hid_num_neurons, max_len_str, number_of_features, dropout=.2)\n",
    "model = seqential_model_compile(model, Adam_optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319b4d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_embed_matrix, y_train, batch_size=32, epochs=epochs, validation_data=(X_val_embed_matrix, y_val),\n",
    "                   callbacks=callbacks_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59db30a1",
   "metadata": {},
   "source": [
    "# With  RMSprob and No Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf79d92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lstm_no_batch_seqential_model_create(hid_num_neurons, max_len_str, number_of_features, dropout=.2)\n",
    "model = seqential_model_compile(model, RMSprop_optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c01491",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_embed_matrix, y_train, batch_size=32, epochs=epochs, validation_data=(X_val_embed_matrix, y_val),\n",
    "                   callbacks=callbacks_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6108087",
   "metadata": {},
   "source": [
    "# With  SGD and Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345f2548",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_ = keras_callbacks(word2vec_type=\"bakr_word2vec\", model_type=\"lstm_with_batch\", learning_rate=learning_rate)\n",
    "callbacks_.append(performance_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9885180",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lstm_with_batch_model_create(hid_num_neurons, max_len_str, number_of_features, dropout=.2)\n",
    "model = seqential_model_compile(model, SGD_optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b044bf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_embed_matrix, y_train, batch_size=32, epochs=epochs, validation_data=(X_val_embed_matrix, y_val),\n",
    "                   callbacks=callbacks_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710f10e3",
   "metadata": {},
   "source": [
    "# With  Adam and No Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c9b1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lstm_with_batch_model_create(hid_num_neurons, max_len_str, number_of_features, dropout=.2)\n",
    "model = seqential_model_compile(model, Adam_optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f32e1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_embed_matrix, y_train, batch_size=32, epochs=epochs, validation_data=(X_val_embed_matrix, y_val),\n",
    "                   callbacks=callbacks_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ec6317",
   "metadata": {},
   "source": [
    "# With  RMSprob and No Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e35a6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lstm_with_batch_model_create(hid_num_neurons, max_len_str, number_of_features, dropout=.2)\n",
    "model = seqential_model_compile(model, RMSprop_optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae74e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_embed_matrix, y_train, batch_size=32, epochs=epochs, validation_data=(X_val_embed_matrix, y_val),\n",
    "                   callbacks=callbacks_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349c9cb3",
   "metadata": {},
   "source": [
    "# LSTM Model with Rezk Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfaa4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_vec_model = load_word2vec_model(\"models/word2vec/rezk_unigram_CBOW_model/train_word2vec_cbow__window_3_min_count_300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585603b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_features = 300\n",
    "\n",
    "callbacks_ = keras_callbacks(word2vec_type=\"rezk_word2vec\", model_type=\"lstm_no_batch\", learning_rate=learning_rate)\n",
    "callbacks_.append(performance_lr)\n",
    "\n",
    "word2vec_path = \"rezk/\"\n",
    "\n",
    "X_train_embed_matrix = text_to_matrix_using_word2vec(word_to_vec_model, x_train_text_tokenized, max_len_str)\n",
    "X_val_embed_matrix = text_to_matrix_using_word2vec(word_to_vec_model, x_val_text_tokenized, max_len_str)\n",
    "\n",
    "# Reshape because of deep learning model\n",
    "X_train_embed_matrix = X_train_embed_matrix.reshape(X_train_embed_matrix.shape[0], max_len_str, number_of_features)\n",
    "X_val_embed_matrix = X_val_embed_matrix.reshape(X_val_embed_matrix.shape[0], max_len_str, number_of_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d2cb5d",
   "metadata": {},
   "source": [
    "# With  SGD and No Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c06bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lstm_no_batch_seqential_model_create(hid_num_neurons, max_len_str, number_of_features, dropout=.2)\n",
    "model = seqential_model_compile(model, SGD_optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc13c790",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_embed_matrix, y_train, batch_size=32, epochs=epochs, validation_data=(X_val_embed_matrix, y_val),\n",
    "                   callbacks=callbacks_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9039b01a",
   "metadata": {},
   "source": [
    "# With  Adam and No Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819acdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lstm_no_batch_seqential_model_create(hid_num_neurons, max_len_str, number_of_features, dropout=.2)\n",
    "model = seqential_model_compile(model, Adam_optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4900d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_embed_matrix, y_train, batch_size=32, epochs=epochs, validation_data=(X_val_embed_matrix, y_val),\n",
    "                   callbacks=callbacks_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e063ebd",
   "metadata": {},
   "source": [
    "# With  Rmsprob and No Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b670cb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lstm_no_batch_seqential_model_create(hid_num_neurons, max_len_str, number_of_features, dropout=.2)\n",
    "model = seqential_model_compile(model, RMSprop_optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f7b283",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_embed_matrix, y_train, batch_size=32, epochs=epochs, validation_data=(X_val_embed_matrix, y_val),\n",
    "                   callbacks=callbacks_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5cd987",
   "metadata": {},
   "source": [
    "# With  SGD and  Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4913a492",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_ = keras_callbacks(word2vec_type=\"rezk_word2vec\", model_type=\"lstm_with_batch\", learning_rate=learning_rate)\n",
    "callbacks_.append(performance_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77200e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lstm_with_batch_model_create(hid_num_neurons, max_len_str, number_of_features, dropout=.2)\n",
    "model = seqential_model_compile(model, SGD_optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8183108f",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_embed_matrix, y_train, batch_size=32, epochs=epochs, validation_data=(X_val_embed_matrix, y_val),\n",
    "                   callbacks=callbacks_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b114d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lstm_with_batch_model_create(hid_num_neurons, max_len_str, number_of_features, dropout=.2)\n",
    "model = seqential_model_compile(model, Adam_optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed077d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_embed_matrix, y_train, batch_size=32, epochs=epochs, validation_data=(X_val_embed_matrix, y_val),\n",
    "                   callbacks=callbacks_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23143f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lstm_with_batch_model_create(hid_num_neurons, max_len_str, number_of_features, dropout=.2)\n",
    "model = seqential_model_compile(model, RMSprop_optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588df895",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_embed_matrix, y_train, batch_size=32, epochs=epochs, validation_data=(X_val_embed_matrix, y_val),\n",
    "                   callbacks=callbacks_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
